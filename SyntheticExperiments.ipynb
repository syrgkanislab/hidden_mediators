{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "nJSbD4Nr8VNq"
   },
   "source": [
    "## Setup Only for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26091,
     "status": "ok",
     "timestamp": 1726010690747,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "j4wBu9BNomlq",
    "outputId": "1ec53172-b732-4692-c04f-a326c223664b"
   },
   "outputs": [],
   "source": [
    "# prompt: mount drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1726010691150,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "JfB4MISjovTQ",
    "outputId": "fcfe2ab8-befa-4ac7-c6db-47e2fb56f7f0"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Colab\\ Notebooks/hidden_mediators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1726010692051,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "D5tm-9Fno5Xn",
    "outputId": "08097071-b875-4577-c8bf-9147c356f9bc"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "MFy1PyP89gR3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "VGF-ucGhpC5P"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "!pip install -r requirements.txt\n",
    "time.sleep(2)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "0wsNOzNVtonf"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# replace `develop` with `install` if you wont make library code changes\n",
    "!python setup.py develop\n",
    "time.sleep(2)\n",
    "clear_output()\n",
    "# Restart the session after running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1726010708657,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "zyL1_6L73Z9e",
    "outputId": "187a0cf7-f7f5-4731-d93b-7ff36c1212de"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "T6FelHd78d8T"
   },
   "source": [
    "# Main Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "a1446bbd-c4be-4846-b09a-e36fad2802ab"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "c79a60f7-dde3-4c7c-8419-ce831b20e824"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from joblib import Parallel, delayed\n",
    "from proximalde.gen_data import gen_data_complex, gen_data_no_controls, gen_data_no_controls_discrete_m\n",
    "from proximalde.proximal import proximal_direct_effect, ProximalDE, residualizeW\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from proximalde.crossfit import fit_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "57abc1f7-1569-469d-8239-12fce056e875"
   },
   "source": [
    "# Running a Single Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "6d25b0a6-3839-42a7-afce-ee0bd39b920d"
   },
   "outputs": [],
   "source": [
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "d = .6  # this can be zero; does not hurt\n",
    "e = .7  # if the product of e*f is small, then we have a weak instrument\n",
    "f = .5  # if the product of e*f is small, then we have a weak instrument\n",
    "g = .9  # this can be zero; does not hurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "2a8593cd-71f2-4cf9-b210-f3225bc0dfd9"
   },
   "outputs": [],
   "source": [
    "n = 50000\n",
    "pw = 1\n",
    "pz, px = 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "rLG9OoLVME8w"
   },
   "outputs": [],
   "source": [
    "# np.random.seed(5)\n",
    "W, D, _, Z, X, Y = gen_data_complex(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "\n",
    "## for no controls un-comment this\n",
    "# _, D, _, Z, X, Y = gen_data_no_controls(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "# W = None\n",
    "\n",
    "## for multi-dimensional mediator uncomment this\n",
    "# pm = 5\n",
    "# full_rank = False\n",
    "# while not full_rank:\n",
    "#     E = np.random.normal(0, 2, (pm, pz))\n",
    "#     F = np.random.normal(0, 2, (pm, px))\n",
    "#     if (np.linalg.matrix_rank(E, tol=0.5) == pm) and (np.linalg.matrix_rank(F, tol=0.5) == pm):\n",
    "#         full_rank = True\n",
    "# W, D, _, Z, X, Y = gen_data_no_controls_discrete_m(n, pw, pz, px, a, b, c, d, e*E, f*F, g, pm=pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's advisable to standardize W, Z, X (in particular the non-binary ones)\n",
    "# and center the binary ones\n",
    "W = StandardScaler().fit_transform(W)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "Z = StandardScaler().fit_transform(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "52002a05-5e4e-4f83-a76c-cd2e0e02cd28"
   },
   "source": [
    "### Using the ProximalDE Estimator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1725928699963,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "83041b59-4dd1-440d-b3b6-275e7fb36159",
    "outputId": "4988fc2d-11f0-4802-97d9-20f5c2914af4"
   },
   "outputs": [],
   "source": [
    "est = ProximalDE(semi=True, cv=3, random_state=4)\n",
    "## or we can use default xgboost models, or interchange linear and xgboost for regression or classiifcation\n",
    "# est = ProximalDE(model_regression='xgb', model_classification='xgb', semi=True, cv=3, random_state=4)\n",
    "# est = ProximalDE(model_regression='linear', model_classification='xgb', semi=True, cv=3, random_state=4)\n",
    "est.fit(W, D, Z, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1725928700395,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "911cd658-57a5-4c30-9900-95770ded7f0b",
    "outputId": "4c763439-9b74-4f07-a831-7da78374b3c4"
   },
   "outputs": [],
   "source": [
    "est.summary(decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1725927674697,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "WlKQ5gKeLx0A",
    "outputId": "e085c1d4-7ff4-4ef4-b305-df64573cb0f5"
   },
   "outputs": [],
   "source": [
    "# tests can also be accessed individually\n",
    "display(est.weakiv_test(alpha=0.05))\n",
    "display(est.idstrength_violation_test(alpha=0.05))\n",
    "display(est.primal_violation_test(alpha=0.05))\n",
    "display(est.dual_violation_test(alpha=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "b4bf6f73-c115-4f04-b1a1-4580df6494bf"
   },
   "source": [
    "#### Covariance Rank Diagnostic for Covariance of Proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "539c686f-e097-4e7f-aa49-c93cf1b35ec6"
   },
   "outputs": [],
   "source": [
    "svalues, svalues_crit = est.covariance_rank_test(calculate_critical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1725835013485,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "481f517a-319c-4494-a9f9-82ba77db47b7",
    "outputId": "6c5afd6c-6c1c-47c7-fe4b-0bd684745a84"
   },
   "outputs": [],
   "source": [
    "plt.title(f\"Number of singular values above threshold: {np.sum(svalues >= svalues_crit)}. \"\n",
    "          f\"Threshold={svalues_crit:.3f}. Top singular value={svalues[0]:.3f}\")\n",
    "plt.scatter(np.arange(len(svalues)), svalues)\n",
    "plt.axhline(svalues_crit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "4a5c7948-4252-471b-a8ef-ebee20030797"
   },
   "source": [
    "#### Confidence Intervals and Robust Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1725302412430,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "3efdc8bf-2a67-472c-9bd2-03612fef1041",
    "outputId": "45864a1b-693b-4447-8e79-a088c7b4bbad"
   },
   "outputs": [],
   "source": [
    "est.conf_int(alpha=.05) # 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1725302412707,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "e0b1e98d-d4b0-42b2-9b08-c04c74a4d759",
    "outputId": "1e9f240e-f387-4841-d682-0a3dab915192"
   },
   "outputs": [],
   "source": [
    "# 95% confidence interval, robust to weak identification\n",
    "est.robust_conf_int(alpha=0.05, lb=.1, ub=1.0, ngrid=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "bcda4ac4-ccea-41a0-a9b9-e54a2cf6d9f8"
   },
   "source": [
    "#### Unusual Data Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "d566ecd4-2574-4f72-a5d2-c9d2e645ad5c"
   },
   "outputs": [],
   "source": [
    "diag = est.run_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1725302413080,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "Qtle13yEbT5o",
    "outputId": "6b85040c-a41c-4538-d1b9-e1000e3c1645"
   },
   "outputs": [],
   "source": [
    "inds = est.influential_set(alpha=0.05)\n",
    "len(inds)  # size of influential set that can flip the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "executionInfo": {
     "elapsed": 119672,
     "status": "ok",
     "timestamp": 1725302532744,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "KHRAV2mgbYLO",
    "outputId": "054f6b4f-d6be-48aa-8607-b306e8f227e8"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "# let's re-train a clone of the estimator on all the data\n",
    "# except the influential set\n",
    "est2 = clone(est)\n",
    "est2.fit(np.delete(W, inds, axis=0), np.delete(D, inds, axis=0),\n",
    "         np.delete(Z, inds, axis=0), np.delete(X, inds, axis=0),\n",
    "         np.delete(Y, inds, axis=0))\n",
    "est2.summary(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1725302533764,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "96d68394-cc6e-49d9-8c90-29822f00b46e",
    "outputId": "bb6f60dc-0c63-48c7-f919-9bb749afec09"
   },
   "outputs": [],
   "source": [
    "diag.cookd_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1725302533764,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "fe0b6501-f2de-40ce-a527-e7613dcedc32",
    "outputId": "c74d6e0d-da24-4d2c-bdfd-b3628826761c"
   },
   "outputs": [],
   "source": [
    "diag.l2influence_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1725302534489,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "aa9a76a8-c1db-4cbd-8504-832030cd4da6",
    "outputId": "7cf670d7-08f2-4698-d2d6-42bf5129b641"
   },
   "outputs": [],
   "source": [
    "diag.influence_plot(influence_measure='cook', npoints=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "executionInfo": {
     "elapsed": 1638,
     "status": "ok",
     "timestamp": 1725302536121,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "c40cc148-0463-431e-b9e2-5fa8b877092a",
    "outputId": "874c50f8-722d-4a06-cbcb-2862160a97d4"
   },
   "outputs": [],
   "source": [
    "diag.influence_plot(influence_measure='l2influence', npoints=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "2ca3adc1-ce7c-4a2b-b832-42ea1e0b60a3"
   },
   "source": [
    "### Subsample-Based Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "executionInfo": {
     "elapsed": 5887,
     "status": "ok",
     "timestamp": 1725234999705,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "9340f9ef-7453-4108-9974-a06005f3fb50",
    "outputId": "56ca676c-bd56-49a9-d00d-ff257ab9a91d"
   },
   "outputs": [],
   "source": [
    "inf = est.bootstrap_inference(stage=3, n_subsamples=1000, fraction=0.5, replace=False, verbose=3, random_state=123)\n",
    "inf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1725234999705,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "7594f89f-47a6-47a5-910d-e2bba3d266c3",
    "outputId": "6d68f449-0f83-4fd4-99b4-84120a16f6f8"
   },
   "outputs": [],
   "source": [
    "plt.hist(inf.point_dist)\n",
    "plt.axvline(inf.point, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "executionInfo": {
     "elapsed": 76509,
     "status": "ok",
     "timestamp": 1725235076211,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "f3967537-e6e1-41f0-b26d-9647f6f3139d",
    "outputId": "88206567-3075-4ade-e8b9-5020ce00b5c9"
   },
   "outputs": [],
   "source": [
    "inf = est.bootstrap_inference(stage=2, n_subsamples=100, fraction=0.5, replace=False, verbose=3, random_state=123)\n",
    "inf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1725235076211,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "d86373a6-c7d6-4afe-a817-116996436819",
    "outputId": "528e9949-caa5-423a-b255-b366a9d53d8a"
   },
   "outputs": [],
   "source": [
    "plt.hist(inf.point_dist)\n",
    "plt.axvline(inf.point, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "id": "893a8afa-12eb-435c-9fdc-99c9e6527f53"
   },
   "outputs": [],
   "source": [
    "inf = est.bootstrap_inference(stage=1, n_subsamples=10, fraction=0.5, replace=False, verbose=3, random_state=123)\n",
    "inf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "id": "d5bb8d5c-6014-4f02-9c6f-6300171839a4"
   },
   "outputs": [],
   "source": [
    "plt.hist(inf.point_dist)\n",
    "plt.vlines([inf.point], 0, 300, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "id": "c9d44d07-5132-45ee-8830-424cc215ee04"
   },
   "outputs": [],
   "source": [
    "inf.summary(pivot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "id": "a482021b-9c5b-4123-b20c-878b2940ee33"
   },
   "source": [
    "# Quality of Procedure and Diagnostics Across Many Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "id": "RBfYb0V9JCQh"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "id": "Yb7c-hsCJDuU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from proximalde.gen_data import gen_data_complex, gen_data_no_controls, gen_data_no_controls_discrete_m\n",
    "from proximalde.proximal import ProximalDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "id": "kbCj0xisicEy"
   },
   "outputs": [],
   "source": [
    "def exp_res(it, n, pw, pm, pz, px, a, b, c, d, e, f, g, sm, *,\n",
    "            dual_type='Z', ivreg_type='adv', n_splits=3, semi=True,\n",
    "            n_jobs=-1, verbose=0):\n",
    "    np.random.seed(it)\n",
    "    if pm > 1:\n",
    "        full_rank = False\n",
    "        while not full_rank:\n",
    "            E = np.random.normal(0, 2, (pm, pz))\n",
    "            F = np.random.normal(0, 2, (pm, px))\n",
    "            if (np.linalg.matrix_rank(E, tol=0.5) == pm) and (np.linalg.matrix_rank(F, tol=0.5) == pm):\n",
    "                full_rank = True\n",
    "        W, D, _, Z, X, Y = gen_data_no_controls_discrete_m(n, pw, pz, px, a, b, c, d, e*E, f*F, g, pm=pm)\n",
    "        if pw == 0:\n",
    "            W = None\n",
    "    elif pw > 0:\n",
    "        # M is unobserved so we omit it from the return variables\n",
    "        W, D, _, Z, X, Y = gen_data_complex(n, pw, pz, px, a, b, c, d, e, f, g, sm=sm)\n",
    "    else:\n",
    "        _, D, _, Z, X, Y = gen_data_no_controls(n, pw, pz, px, a, b, c, d, e, f, g, sm=sm)\n",
    "        W = None\n",
    "\n",
    "    W = StandardScaler().fit_transform(W)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    Z = StandardScaler().fit_transform(Z)\n",
    "    est = ProximalDE(cv=n_splits, semi=semi, binary_D=True,\n",
    "                     dual_type=dual_type, ivreg_type=ivreg_type,\n",
    "                     n_jobs=n_jobs, random_state=it, verbose=verbose)\n",
    "    est.fit(W, D, Z, X, Y)\n",
    "    weakiv_stat, _, _, weakiv_crit = est.weakiv_test(alpha=0.05)\n",
    "    idstr, _, _, idstr_crit = est.idstrength_violation_test(alpha=0.05)\n",
    "    pval, _, _, pval_crit = est.primal_violation_test(alpha=0.05)\n",
    "    dval, _, _, dval_crit = est.dual_violation_test(alpha=0.05)\n",
    "    lb, ub = est.robust_conf_int(lb=-2, ub=2)\n",
    "    return est.point_, est.stderr_, est.r2D_, est.r2Z_, est.r2X_, est.r2Y_, \\\n",
    "        idstr, idstr_crit, est.point_pre_, est.stderr_pre_, \\\n",
    "        pval, pval_crit, dval, dval_crit, weakiv_stat, weakiv_crit, \\\n",
    "        lb, ub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "blGY8rsUPTvM"
   },
   "source": [
    "```\n",
    "a : strength of D -> M edge\n",
    "b : strength of M -> Y edge\n",
    "c : strength of D -> Y edge\n",
    "d : strength of D -> Z edge\n",
    "e : strength of M -> Z edge\n",
    "f : strength of M -> X edge\n",
    "g : strength of X -> Y edge\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43519,
     "status": "ok",
     "timestamp": 1726007566516,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "049c9f10-c821-4b00-bcce-c850162c5c23",
    "outputId": "4fcb5dd9-af01-4d6c-c36c-4b03bdee04f2"
   },
   "outputs": [],
   "source": [
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "d = .5  # this can be zero; does not hurt\n",
    "e = .5  # if the product of e*f is small, then we have a weak instrument\n",
    "f = .5  # if the product of e*f is small, then we have a weak instrument\n",
    "g = .5  # this can be zero; does not hurt\n",
    "sm = 2.0  # strength of mediator noise; needs to be non-zero for identifiability; only used when pm=1.\n",
    "n = 10000\n",
    "pw = 1\n",
    "pm = 1\n",
    "pz, px = 2, 2\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=3)(delayed(exp_res)(i, n, pw, pm, pz, px, a, b, c, d, e, f, g, sm,\n",
    "                                                          dual_type='Z', ivreg_type='adv',\n",
    "                                                          n_splits=3, semi=True, n_jobs=1)\n",
    "                                          for i in range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "id": "e936273a-0829-4c8b-bd86-e3fb929a296c"
   },
   "source": [
    "#### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1726007566516,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "26cc2396-5f19-4ad5-8266-3a48a7b7c2bc",
    "outputId": "2ba44ffc-5ec8-4c92-ff7b-1798a8db4ac2"
   },
   "outputs": [],
   "source": [
    "points_base, stderrs_base, rmseD, rmseZ, rmseX, rmseY, \\\n",
    "    idstr, idstr_crit, points_alt, stderrs_alt, \\\n",
    "    pval, pval_crit, dval, dval_crit, wiv_stat, wiv_crit, \\\n",
    "    rlb, rub = map(np.array, zip(*results))\n",
    "\n",
    "points_base = np.array(points_base)\n",
    "stderrs_base = np.array(stderrs_base)\n",
    "points_alt = np.array(points_alt)\n",
    "stderrs_alt = np.array(stderrs_alt)\n",
    "\n",
    "print(\"Estimation Quality\")\n",
    "for name, points, stderrs in [('Debiased', points_base, stderrs_base), ('Regularized', points_alt, stderrs_alt)]:\n",
    "    print(f\"\\n{name} Estimate\")\n",
    "    coverage = np.mean((points + 1.96 * stderrs >= c) & (points - 1.96 * stderrs <= c))\n",
    "    rmse = np.sqrt(np.mean((points - c)**2))\n",
    "    bias = np.abs(np.mean(points) - c)\n",
    "    std = np.std(points)\n",
    "    mean_stderr = np.mean(stderrs)\n",
    "    mean_length = np.mean(2 * 1.96 * stderrs)\n",
    "    median_length = np.median(2 * 1.96 * stderrs)\n",
    "    print(f\"Coverage: {coverage:.3f}\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"Bias: {bias:.3f}\")\n",
    "    print(f\"Std: {std:.3f}\")\n",
    "    print(f\"Mean CI length: {mean_length:.3f}\")\n",
    "    print(f\"Median CI length: {mean_length:.3f}\")\n",
    "    print(f\"Mean Estimated Stderr: {mean_stderr:.3f}\")\n",
    "    print(f\"Nuisance R^2 (D, Z, X, Y): {np.mean(rmseD):.3f}, {np.mean(rmseZ):.3f}, {np.mean(rmseX):.3f}, {np.mean(rmseY):.3f}\")\n",
    "\n",
    "print(\"\\nRobust ConfInt Coverage\")\n",
    "rcoverage = np.mean((rub >= c) & (rlb <= c))\n",
    "print(f\"Robust Coverage: {rcoverage:.3f}\")\n",
    "\n",
    "print(\"\\nViolations\")\n",
    "for name, stat, crit in [('Id-Strenth', idstr, idstr_crit), ('WeakIV F-test', wiv_stat, wiv_crit)]:\n",
    "    violation = np.mean(stat <= crit)\n",
    "    print(f\"% Violations of {name}: {violation:.3f}\")\n",
    "for name, stat, crit in [('Primal Existence', pval, pval_crit), ('Dual Existence', dval, dval_crit)]:\n",
    "    violation = np.mean(stat >= crit)\n",
    "    print(f\"% Violations of {name}: {violation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1726007566975,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "FpysCHFz6PC5",
    "outputId": "29158bab-98bd-4cba-ed9e-627a943d9dc7"
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(f\"{np.mean(dval > scipy.stats.chi2(df=px).ppf(.95))} vs 0.05, {np.mean(dval, axis=0):.3f} vs {px}, {np.var(dval, axis=0):.3f} vs {2*px}\")\n",
    "plt.hist(dval)\n",
    "plt.axvline(scipy.stats.chi2(df=px).ppf(.95), color='r')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(f\"{np.mean(pval > scipy.stats.chi2(df=pz + 1).ppf(.95))} vs 0.05, \"\n",
    "          f\"{np.mean(pval, axis=0):.3f} vs {pz + 1}, {np.var(pval, axis=0):.3f} vs {2*(pz + 1)}\")\n",
    "plt.hist(pval)\n",
    "plt.axvline(scipy.stats.chi2(df=pz + 1).ppf(.95), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1726007567201,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "oVh3Nb0W9SF1",
    "outputId": "821a32e7-1c93-457f-98f0-f6b69081fabe"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "import scipy.stats\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "qqplot(np.array(dval), dist=scipy.stats.chi2(df=px), line='45', ax=ax)\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "qqplot(np.array(pval), dist=scipy.stats.chi2(df=pz+1), line='45', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1726007567642,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "ac39fd4a-fd3e-48d5-8a33-f187bf955c9f",
    "outputId": "5f792655-c35c-4367-95c3-c5eba7a499f7"
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(f\"{np.mean(idstr / idstr_crit > 1)} vs. 0.05, {np.mean(idstr / idstr_crit, axis=0):.3f}\")\n",
    "plt.hist(idstr)\n",
    "plt.axvline(np.mean(idstr_crit), color='r')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(f\"{np.mean(wiv_stat):.3f}, {np.mean(wiv_stat / wiv_crit, axis=0):.3f}\")\n",
    "plt.hist(wiv_stat)\n",
    "plt.axvline(np.mean(wiv_crit), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1726007567842,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "8aa77e2c-305e-4638-a8cf-03a26062436c",
    "outputId": "5f6e070e-39f1-4818-bbb7-0dd52d6fb983"
   },
   "outputs": [],
   "source": [
    "plt.hist(points_base, label='Distribution of Estimates: debiased')\n",
    "plt.hist(points_alt, label='Distribution of Estimates: original', alpha=.3)\n",
    "plt.vlines([c], 0, plt.ylim()[1], color='red', label='truth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "# Using Custom ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from joblib import Parallel, delayed\n",
    "from proximalde.gen_data import gen_data_complex, gen_data_no_controls, gen_data_no_controls_discrete_m\n",
    "from proximalde.proximal import proximal_direct_effect, ProximalDE, residualizeW\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from proximalde.crossfit import fit_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class XGBRegressorWrapper(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, *, max_depth=3, early_stopping_rounds=50, learning_rate=.1):\n",
    "        self.max_depth = max_depth\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=.2)\n",
    "        self.model_ = XGBRegressor(max_depth=self.max_depth,\n",
    "                                   early_stopping_rounds=self.early_stopping_rounds,\n",
    "                                   learning_rate=self.learning_rate, random_state=123)\n",
    "        self.model_.fit(Xtrain, ytrain, eval_set=[(Xval, yval)], verbose=False)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "\n",
    "class XGBClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, *, max_depth=3, early_stopping_rounds=50, learning_rate=.1):\n",
    "        self.max_depth = max_depth\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=.2)\n",
    "        self.model_ = XGBClassifier(max_depth=self.max_depth,\n",
    "                                   early_stopping_rounds=self.early_stopping_rounds,\n",
    "                                   learning_rate=self.learning_rate, eval_metric='logloss', random_state=123)\n",
    "        self.model_.fit(Xtrain, ytrain, eval_set=[(Xval, yval)], verbose=False)\n",
    "        self.classes_ = self.model_.classes_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model_.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "d = .6  # this can be zero; does not hurt\n",
    "e = .7  # if the product of e*f is small, then we have a weak instrument\n",
    "f = .5  # if the product of e*f is small, then we have a weak instrument\n",
    "g = .9  # this can be zero; does not hurt\n",
    "n = 50000\n",
    "pw = 10\n",
    "pz, px = 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "W, D, _, Z, X, Y = gen_data_complex(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "\n",
    "## for no controls un-comment this\n",
    "# _, D, _, Z, X, Y = gen_data_no_controls(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "# W = None\n",
    "\n",
    "## for multi-dimensional mediator uncomment this\n",
    "# pm = 5\n",
    "# full_rank = False\n",
    "# while not full_rank:\n",
    "#     E = np.random.normal(0, 2, (pm, pz))\n",
    "#     F = np.random.normal(0, 2, (pm, px))\n",
    "#     if (np.linalg.matrix_rank(E, tol=0.5) == pm) and (np.linalg.matrix_rank(F, tol=0.5) == pm):\n",
    "#         full_rank = True\n",
    "# W, D, _, Z, X, Y = gen_data_no_controls_discrete_m(n, pw, pz, px, a, b, c, d, e*E, f*F, g, pm=pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "est = ProximalDE(model_regression=XGBRegressorWrapper(), model_classification=XGBClassifierWrapper(),\n",
    "                 cv=3, semi=False, n_jobs=-1, random_state=3, verbose=3)\n",
    "est.fit(W, D, Z, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## And with HyperParam Tuning and Semi-Crossfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regression = GridSearchCV(XGBRegressorWrapper(), {'learning_rate': [.01, .1, 1]}, scoring='neg_root_mean_squared_error')\n",
    "classification = GridSearchCV(XGBClassifierWrapper(), {'learning_rate': [.01, .1, 1]}, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "est = ProximalDE(model_regression=regression, model_classification=classification,\n",
    "                 cv=3, semi=True, n_jobs=-1, random_state=3, verbose=3)\n",
    "est.fit(W, D, Z, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## And even gcv among many types of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proximalde.utilities import GridSearchCVList\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "\n",
    "regression = GridSearchCVList([XGBRegressorWrapper(), Lasso()],\n",
    "                              [{'learning_rate': [.01, .1, 1]},\n",
    "                               {'alpha': np.logspace(-4, 2, 20)}],\n",
    "                              scoring='neg_root_mean_squared_error')\n",
    "classification = GridSearchCVList([XGBClassifierWrapper(),\n",
    "                                   LogisticRegression(penalty='l1', solver='liblinear',\n",
    "                                                      tol=1e-6, intercept_scaling=100)],\n",
    "                                  [{'learning_rate': [.01, .1, 1]},\n",
    "                                   {'C': np.logspace(-4, 4, 10)}],\n",
    "                                  scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "est = ProximalDE(model_regression=regression, model_classification=classification,\n",
    "                 cv=3, semi=True, n_jobs=-1, random_state=3, verbose=3)\n",
    "est.fit(W, D, Z, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {
    "id": "M0Zp1JDoZBbi"
   },
   "source": [
    "# Mediations that Trigger Violations of Both Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1725935425853,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "Ts2i4pRkZ87z",
    "outputId": "b36714c4-b128-4579-b4a0-cab4ce99ba96"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "id": "Cr_1N_wdZ7yp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from joblib import Parallel, delayed\n",
    "from proximalde.proximal import ProximalDE\n",
    "from proximalde.gen_data import gen_data_with_mediator_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "id": "fObwIvAzaKXy"
   },
   "outputs": [],
   "source": [
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "d = .0  # this can be zero; does not hurt\n",
    "e = .7  # if the product of e*f is small, then we have a weak instrument\n",
    "f = .5  # if the product of e*f is small, then we have a weak instrument\n",
    "g = .9  # this can be zero; does not hurt\n",
    "\n",
    "n = 100000\n",
    "pw = 100\n",
    "pz, px = 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "id": "lv6zb4EKZgeC"
   },
   "outputs": [],
   "source": [
    "W, D, _, Z, X, Y = gen_data_with_mediator_violations(n, pw, pz, px, a, b, c, d, e, f, g,\n",
    "                                                     invalidZinds=[0], invalidXinds=[1])\n",
    "W = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1726007694659,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "2mRCLSaQaN1g",
    "outputId": "e57ee7d5-f1a4-4b09-f12f-f3a5f15ad91d"
   },
   "outputs": [],
   "source": [
    "est = ProximalDE(cv=3, semi=True, n_jobs=-1, random_state=3, verbose=3)\n",
    "est.fit(W, D, Z, X, Y)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {
    "id": "3FH5cxTvaSNn"
   },
   "source": [
    "## Explanation\n",
    "\n",
    "For the primal moment to hold, we essentially need that:\n",
    "\\begin{equation}\n",
    "\\text{Cov}(Y, DZ) \\in \\text{column-span}(\\text{Cov}(DZ, DX))\n",
    "\\end{equation}\n",
    "where $DZ, DX$ are the concatenation of $D$ with $Z$ and $X$ correspondingly. Roughly this should be satisfied if:\n",
    "\\begin{equation}\n",
    "\\text{Cov}(Y, Z) \\in \\text{column-span}(\\text{Cov}(Z, X))\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "For the dual moment to hold, we essentially need that:\n",
    "\\begin{equation}\n",
    "\\text{Cov}(D, X) \\in \\text{column-span}(\\text{Cov}(X, Z)) = \\text{row-span}(\\text{Cov}(Z, X))\n",
    "\\end{equation}\n",
    "\n",
    "Let's verify that this is indeed not the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "id": "FoJIsFrvZjek"
   },
   "outputs": [],
   "source": [
    "Z = Z - np.mean(Z, axis=0)\n",
    "X = X - np.mean(X, axis=0)\n",
    "D = D - np.mean(D, axis=0)\n",
    "Y = Y - np.mean(Y, axis=0)\n",
    "D = D.reshape(-1, 1)\n",
    "Y = Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {
    "id": "cWBVt96YbEiH"
   },
   "source": [
    "Let's calculate the three relevant covariances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "id": "lPoi2F90ZoZu"
   },
   "outputs": [],
   "source": [
    "CovZX = Z.T @ X / n\n",
    "CovXD = X.T @ D / n\n",
    "CovYZ = Z.T @ Y / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {
    "id": "vIZnkfFdbOBi"
   },
   "source": [
    "Let's investigate the condition for the existence of the dual, so we need $Cov(X,D)$ to be in the row span of $Cov(Z,X)$, equivalently, column span of $Cov(X, Z)$. We perform a singular value decomposition and take only the significant non-zero eigenvalues. This can be done by using the critical value computed by the \"covariance_rank_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1726007699711,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "1jLVEcjSbsM_",
    "outputId": "7f6f93a1-960a-4cbb-c63b-5ab7a380d453"
   },
   "outputs": [],
   "source": [
    "_, Scrit = est.covariance_rank_test(calculate_critical=True)\n",
    "Scrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "id": "nIsX8XmNZw4v"
   },
   "outputs": [],
   "source": [
    "U, S, Vh = np.linalg.svd(CovZX, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1726007700552,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "9AHaG6jWbvaN",
    "outputId": "1b17e7cd-ea80-4c65-9c33-5e730a960a0d"
   },
   "outputs": [],
   "source": [
    "# row span of CovZX, with stat-sig non-zero singular values, vs CovXD\n",
    "print(\"Basis of row span of CovZX:\\n\", Vh[:, S > Scrit], \"\\n\",\n",
    "      \"Vector CovXD:\\n\", CovXD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {
    "id": "lzvD9gE6cjgJ"
   },
   "source": [
    "We see that $CovXD\\approx (0.12, 0.12)$, while the row span of CovZX is the subspace spanned by approximately the single vector $(-1, 0)$, i.e. multiples of this single vector. So obviously, the first vector is not in that subspace.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {
    "id": "pTr0iPt6c70t"
   },
   "source": [
    "Let's examine the primal existence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1726007703508,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "9jIOSovrcKty",
    "outputId": "b71a6ba4-6a02-48f4-ee6a-50b95dae9e0e"
   },
   "outputs": [],
   "source": [
    "# column span of CovZX, with stat-sig non-zero singular values, vs CovXD\n",
    "print(\"Basis of column span of CovZX:\\n\", U[:, S > Scrit], \"\\n\",\n",
    "      \"Vector CovYZ:\\n\", CovYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {
    "id": "hd9iZywudNhQ"
   },
   "source": [
    "We see that $CovYZ\\approx (7.5, 6.5)$, while the column span of CovZX is the subspace spanned by the single vector $(-.7, -.7)$, i.e. multiples of this single vector. So obviously, the first vector is not in that subspace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "## Fixing the Violation by Removing Z's and X's\n",
    "\n",
    "In the above example it was $Z[0]$ that had a violation with $Y$ and $X[1:]$ that had a violation with $D$. So potentially if we remove $Z[0]$ and if we remove $X[1:]$ we would get an unbiased estimate.\n",
    "\n",
    "Of course, this would be ok only if $D$ does not have a direct effect on the Z's we removed (in this case $Z[0]$), as otherwise, by removing $Z[0]$, there is another mediation path through $Z[0]$ that we are not controlling for and the effect we are estimating is also the effect mediated through the path $D->Z[0]->Y$. \n",
    "\n",
    "So even though removing $Z[0]$ and $X[1:]$ will always lead to the violations not being flagged, the estimate will be the correct estimate only when $d=0$, i.e. the direct effect from $D->Z[0]$ is $0$.\n",
    "\n",
    "Similarly, removing $X[1:]$ is ok, only if the direct effect of these X's to Y is zero. Otherwise, by removing these X's we are removing the mediation paths $D->X->Y$ and not controlling for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from joblib import Parallel, delayed\n",
    "from proximalde.proximal import ProximalDE\n",
    "from proximalde.gen_data import gen_data_with_mediator_violations, gen_data_no_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "d = .0  # this can be zero; does not hurt\n",
    "e = .7  # if the product of e*f is small, then we have a weak instrument\n",
    "f = .5  # if the product of e*f is small, then we have a weak instrument\n",
    "g = .0  # this can be zero; does not hurt\n",
    "\n",
    "n = 100000\n",
    "pw = 100\n",
    "pz, px = 50, 40\n",
    "invalidZ = [0, 4, 5]\n",
    "invalidX = [0, 6, 8]\n",
    "validZ = np.setdiff1d(np.arange(pz), invalidZ)\n",
    "validX = np.setdiff1d(np.arange(px), invalidX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, D, _, Z, X, Y = gen_data_with_mediator_violations(n, pw, pz, px, a, b, c, d, e, f, g,\n",
    "                                                     invalidZinds=invalidZ, invalidXinds=invalidX)\n",
    "W = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ProximalDE(cv=3, random_state=3, verbose=3)\n",
    "est.fit(W, D, Z, X, Y)\n",
    "display(est.summary().tables[0], est.summary().tables[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ProximalDE(cv=3, random_state=3, verbose=3)\n",
    "est.fit(W, D, Z[:, validZ], X[:, validX], Y)\n",
    "display(est.summary().tables[0], est.summary().tables[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "Let's see if we can identify this subset using a data-driven approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proximalde.utilities import covariance, svd_critical_value\n",
    "from proximalde.proximal import residualizeW\n",
    "\n",
    "# Order the Z's in decreasing order of orthogonality\n",
    "Dres, Zres, Xres, Yres, *_ = residualizeW(W, D, Z, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "covXD = covariance(Xres, Dres)\n",
    "covZY = covariance(Zres, Yres)\n",
    "covXZ = covariance(Xres, Zres)\n",
    "\n",
    "# replacing covariance with low rank component, cleaning up the noisy eigenvalues\n",
    "U, S, Vh = scipy.linalg.svd(covXZ, full_matrices=False)\n",
    "Scrit = svd_critical_value(Xres, Zres)\n",
    "covXZ = U[:, S > Scrit] @ np.diag(S[S > Scrit]) @ Vh[S > Scrit, :]\n",
    "\n",
    "# cleaning up cov(X,D) and cov(Z,Y) to zero-out the statistical zeros\n",
    "stderr_covXD = np.sqrt(np.var((Xres - Xres.mean(axis=0)) * (Dres - Dres.mean(axis=0)), axis=0) / Xres.shape[0])\n",
    "covXD[np.abs(covXD).flatten() < 1.96 * stderr_covXD] = 0\n",
    "stderr_covZY = np.sqrt(np.var((Zres - Zres.mean(axis=0)) * (Yres - Yres.mean(axis=0)), axis=0) / Zres.shape[0])\n",
    "covZY[np.abs(covZY).flatten() < 1.96 * stderr_covZY] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "covDZY = np.zeros((1 + Z.shape[1], 1))\n",
    "covDZY[1:, :] = covZY\n",
    "covDZY[0, :] = covariance(Dres, Yres).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "DZ = np.hstack([Dres, Zres])\n",
    "covDDZ = covariance(D, DZ)\n",
    "\n",
    "covDXDZ = np.zeros((1 + Xres.shape[1], 1 + Zres.shape[1]))\n",
    "covDXDZ[1:, 1:] = covXZ\n",
    "covDXDZ[0, :] = covDDZ.flatten()\n",
    "covDXDZ[1:, 0] = covXD.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def violation(remnantX, remnantZ):\n",
    "    covXZ_tmp = covXZ[remnantX, :][:, remnantZ]\n",
    "    covZX_tmp = covXZ_tmp.T\n",
    "    covXD_tmp = covXD[remnantX]\n",
    "    covZY_tmp = covZY[remnantZ]\n",
    "    dual_violation = np.linalg.norm(covXD_tmp - covXZ_tmp @ scipy.linalg.pinv(covXZ_tmp) @ covXD_tmp, ord=np.inf)\n",
    "    primal_violation = np.linalg.norm(covZY_tmp - covZX_tmp @ scipy.linalg.pinv(covZX_tmp) @ covZY_tmp, ord=np.inf)\n",
    "\n",
    "    ## more accurate primal violation\n",
    "    # covDXDZ_tmp = covDXDZ[[0] + [i + 1 for i in remnantX], :][:, [0] + [i + 1 for i in remnantZ]]\n",
    "    # covDZDX_tmp = covDXDZ_tmp.T\n",
    "    # covDZY_tmp = covDZY[[0] + [i + 1 for i in remnantZ]]\n",
    "    # primal_violation = np.linalg.norm(covDZY_tmp - covDZDX_tmp @ scipy.linalg.pinv(covDZDX_tmp) @ covDZY_tmp, ord=np.inf)\n",
    "\n",
    "    return dual_violation, primal_violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "violation(list(validX), list(validZ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_bench, pv_bench = violation(np.arange(Xres.shape[1]), np.arange(Zres.shape[1]))\n",
    "dv_bench, pv_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def xset_trial(it, remnantZ, verbose):\n",
    "    ''' We try to add elements to the X's in random order, while maintaining that the dual\n",
    "    violation is not violated. Here we use all the Z's, since the dual violation can only\n",
    "    improve if we add more Z's.\n",
    "    '''\n",
    "    np.random.seed(it)\n",
    "    unusedX = np.arange(Xres.shape[1])\n",
    "    remnantX = []\n",
    "    while len(unusedX) > 0:\n",
    "        next = np.random.choice(len(unusedX), size=1)[0]\n",
    "        dv, pv = violation(remnantX + [unusedX[next]], remnantZ)\n",
    "        if dv < 0.1 * dv_bench:\n",
    "            remnantX += [unusedX[next]]\n",
    "        unusedX = np.delete(unusedX, next)\n",
    "\n",
    "    if remnantX:\n",
    "        remnantX = np.sort(remnantX)\n",
    "        if verbose:\n",
    "            print(remnantX, violation(remnantX, remnantZ))\n",
    "    \n",
    "        ohe = np.zeros(Xres.shape[1]).astype(int)\n",
    "        ohe[remnantX] = 1\n",
    "        return ohe\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def zset_trial(it, remnantX, verbose):\n",
    "    ''' Given a candidate X set, we try to add elements to the Z's in random order,\n",
    "    while maintaining that the primal violation does not occur.\n",
    "    '''\n",
    "    np.random.seed(it)\n",
    "    \n",
    "    unusedZ = np.arange(Zres.shape[1])\n",
    "    remnantZ = []\n",
    "    while len(unusedZ) > 0:\n",
    "        next = np.random.choice(len(unusedZ), size=1)[0]\n",
    "        dv, pv = violation(remnantX, remnantZ + [unusedZ[next]])\n",
    "        if pv < 0.1 * pv_bench:\n",
    "            remnantZ += [unusedZ[next]]\n",
    "        unusedZ = np.delete(unusedZ, next)\n",
    "\n",
    "    if remnantZ:\n",
    "        remnantZ = np.sort(remnantZ)\n",
    "    \n",
    "        dv, pv = violation(remnantX, remnantZ)\n",
    "        if verbose:\n",
    "            print(remnantX, remnantZ, dv, pv)\n",
    "    \n",
    "        ohe = np.zeros(Xres.shape[1] + Zres.shape[1]).astype(int)\n",
    "        ohe[remnantX] = 1\n",
    "        ohe[Xres.shape[1] + remnantZ] = 1\n",
    "        return ohe\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_candidate_sets(ntrials, verbose=0, n_jobs=-1):\n",
    "    unique_Zsets = np.array([np.ones(Zres.shape[1])]).astype(int)\n",
    "\n",
    "    for _ in range(2):\n",
    "        # we generate a set of candidate of maximal X sets such that the dual violation does not\n",
    "        # occur, when we use all the Z's. Note that more Z's can only help the dual.\n",
    "        candidateX = []\n",
    "        for remnantZ in unique_Zsets:\n",
    "            remnantZ = np.argwhere(remnantZ).flatten()\n",
    "            candidateX += Parallel(n_jobs=n_jobs, verbose=3)(delayed(xset_trial)(it, remnantZ, verbose)\n",
    "                                                             for it in range(ntrials))\n",
    "        candidateX = [c for c in candidateX if c is not None]\n",
    "\n",
    "        if not candidateX:\n",
    "            return []\n",
    "\n",
    "        candidateX = np.array(candidateX).astype(int)\n",
    "        # we clean up to keep only the unique solutions\n",
    "        unique_Xsets = np.unique(candidateX, axis=0)\n",
    "    \n",
    "        candidateXZ = []\n",
    "        # for each unique candidate solution of X's\n",
    "        for remnantX in unique_Xsets:\n",
    "            remnantX = np.argwhere(remnantX).flatten()\n",
    "            # we try to construct maximal sets of Z's, such that the primal violation\n",
    "            # does not occur. Note that more X's can only help the primal, which is why\n",
    "            # we tried to build maximal X's in the first place.\n",
    "            candidateXZ += Parallel(n_jobs=n_jobs, verbose=3)(delayed(zset_trial)(it, remnantX, verbose)\n",
    "                                                              for it in range(ntrials))\n",
    "        candidateXZ = [c for c in candidateXZ if c is not None]\n",
    "\n",
    "        if not candidateXZ:\n",
    "            return []\n",
    "\n",
    "        # this array now contains the one-hot-encodings of the Xset and the Zset (concatenated)\n",
    "        candidateXZ = np.array(candidateXZ).astype(int)\n",
    "        # we clean up to keep only unique Zset solutions\n",
    "        unique_Zsets = np.unique(candidateXZ[:, Xres.shape[1]:], axis=0)\n",
    "\n",
    "    # we clean up to keep only unique pairs of solutions\n",
    "    unique_XZsets = np.unique(candidateXZ, axis=0)\n",
    "    # we transform the one hot encodings back to member sets\n",
    "    final_candidates = []\n",
    "    for unique_XZ in unique_XZsets:\n",
    "        Xset = np.argwhere(unique_XZ[:Xres.shape[1]]).flatten()\n",
    "        Zset = np.argwhere(unique_XZ[Xres.shape[1]:]).flatten()\n",
    "        dv, pv = violation(Xset, Zset)\n",
    "        if verbose:\n",
    "            print(Xset, Zset, dv, pv)\n",
    "        if pv < 0.1 * pv_bench and dv < 0.1 * dv_bench:\n",
    "            final_candidates += [(Xset, Zset)]\n",
    "    return final_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = find_candidate_sets(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Xset, Zset in candidates:\n",
    "    print(\"Xset =\", Xset)\n",
    "    print(\"Deleted Xs =\", np.setdiff1d(np.arange(Xres.shape[1]), Xset))\n",
    "    print(\"Zset =\", Zset)\n",
    "    print(\"Deleted Zs =\", np.setdiff1d(np.arange(Zres.shape[1]), Zset))\n",
    "    est = ProximalDE(random_state=3)\n",
    "    est.fit(None, Dres, Zres[:, Zset], Xres[:, Xset], Yres)\n",
    "    display(est.summary().tables[0], est.summary().tables[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {
    "id": "VK9mJbE-fNsu"
   },
   "source": [
    "# Semi-Synthetic Data Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {
    "id": "hJUqcqoufNs3"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1726018077607,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "fxF9peCrfNs3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from joblib import Parallel, delayed\n",
    "from proximalde.proximal import ProximalDE, residualizeW\n",
    "from proximalde.gen_data import gen_data_with_mediator_violations, gen_data_no_controls_discrete_m, gen_data_no_controls, gen_data_complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {
    "id": "aXezYVsxfhIQ"
   },
   "source": [
    "Suppose we are given some real-world dataset $(W, D, Z, X, Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1726018081693,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "MIpvQby9fNs4"
   },
   "outputs": [],
   "source": [
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "d = .6  # this can be zero; does not hurt\n",
    "e = .7  # if the product of e*f is small, then we have a weak instrument\n",
    "f = .5  # if the product of e*f is small, then we have a weak instrument\n",
    "g = .9  # this can be zero; does not hurt\n",
    "\n",
    "n = 100000\n",
    "pw = 100\n",
    "pz, px = 10, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1726018083054,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "CMHwvUYkfNs4"
   },
   "outputs": [],
   "source": [
    "np.random.seed(124)\n",
    "W, D, _, Z, X, Y = gen_data_with_mediator_violations(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "W = None\n",
    "\n",
    "# W, D, _, Z, X, Y = gen_data_complex(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "\n",
    "## for no controls un-comment this\n",
    "# _, D, _, Z, X, Y = gen_data_no_controls(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "# W = None\n",
    "\n",
    "## for multi-dimensional mediator uncomment this\n",
    "# pm = 5\n",
    "# full_rank = False\n",
    "# while not full_rank:\n",
    "#     E = np.random.normal(0, 2, (pm, pz))\n",
    "#     F = np.random.normal(0, 2, (pm, px))\n",
    "#     if (np.linalg.matrix_rank(E, tol=0.5) == pm) and (np.linalg.matrix_rank(F, tol=0.5) == pm):\n",
    "#         full_rank = True\n",
    "# W, D, _, Z, X, Y = gen_data_no_controls_discrete_m(n, pw, pz, px, a, b, c, d, e*E, f*F, g, pm=pm)\n",
    "# W = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1726018083441,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "9_LP_IZnjkFY",
    "outputId": "800158a5-d005-4f37-a16d-e1aab11658dc"
   },
   "outputs": [],
   "source": [
    "# as we said this dgp violates the assumptions so the test will fail\n",
    "est = ProximalDE(cv=3, semi=True, n_jobs=-1, random_state=3, verbose=3)\n",
    "est.fit(W, D, Z, X, Y)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {
    "id": "InB0JdLSf1p6"
   },
   "source": [
    "## Semi-Synthetic Generation Process\n",
    "We will create a semi-synthetic DGP as follows. We first find the top component of the covariance of $(Z - E[Z|W], X - E[X|W])$, by running a singular value decomposition.\n",
    "\n",
    "We can think of the statistically non-zero singular values of this covariance matrix as the latent factor model. If the svd decomposition of $Cov(Z, X)$ is $G \\cdot S \\cdot F'$, then such an SVD can be generated under the following latent factor model:\n",
    "\\begin{align}\n",
    "Z =& G M + \\epsilon_Z\n",
    "X =& F M + \\epsilon_X\n",
    "\\end{align}\n",
    "where $\\epsilon_Z$ and $\\epsilon_X$ are independent and $G$ and $F$ are the\n",
    "eigenvectors found by the SVD. Note that under this structural model:\n",
    "\\begin{align}\n",
    "Cov(Z, X) = G E[MM'] F'\n",
    "\\end{align}\n",
    "Hence, if $E[MM'] = diagonal(s_1, ..., s_K)$, then the covariance of the Z,X generated by the above structural model is the same as the covariance we calculated. Thus we can generate $Z, X$ that match this covariance, by first generating a mediator $M$ based on a normal r.v. with covariance $diagonal(s_1, ..., s_K)$ and then generate $Z$ and $X$ based on the structural equations above. For this we also need the distribution of $\\epsilon_Z$ and $\\epsilon_X$. As a proxy we can use the marginal distribution of $Z$ and $X$ from the data (i.e. marginalizing the empirical distribution). We can also use the marginal distribution of the projected $Z$ and $X$ after we project out the non-orthogonal components to the eigenvectors $G$ and $F$ correspondingly. The latter has the guarantee that it only contains the epsilon parts, but does not preserve the variance of the original variables. So we aire for the first approach.\n",
    "\n",
    "Moreover, we generate the mediator as follows. We learn a propensity model $E[D|W]$ and we generate a treatment $D$ by sampling from the propensity. Then we  set the value of the mediator to be:\n",
    "\\begin{equation}\n",
    "\\tilde{M} = a \\cdot D + \\epsilon_M\n",
    "\\end{equation}\n",
    "so that the mediator is affected by the treatment, where $\\epsilon_M$ is a multi-variate gaussian with diagonals as described above. \n",
    "\n",
    "Then we also impute outcomes:\n",
    "\\begin{equation}\n",
    "\\tilde{Y} = f_Y(\\tilde{M}, D, \\tilde{X}, \\epsilon_Y)\n",
    "\\end{equation}\n",
    "The reason why we want to resample D is to break any violating mediation paths $D->Mp->X$ that might exist in the original data, which would create a failure in this new dataset, if we didn't resample the treatment. We could try not resampling the treatment. If then we get a failure of the dual violation, then this hints at an auxiliary violating mediation path $D->Mp->X$.\n",
    "\n",
    "Now for every sample $(W, D, Z, X, Y)$ in the original dataset, we now have a sample $(W, \\tilde{D}, \\tilde{Z}, \\tilde{X}, \\tilde{Y})$, where $W$ is real, $\\tilde{D}$ is sampled from the estimated propensity, given $W$, and $\\tilde{Z}, \\tilde{X}$ are slight modifications of the real $X,Z$ along only a particular direction and $\\tilde{Y}$ is fully synthetic.\n",
    "\n",
    "\n",
    "For simplicity, we will first choose linear structural function $f_Y$:\n",
    "\\begin{align}\n",
    "f_Y(M, D, X, \\epsilon_Y) =& b M + c D + g X[:, 0] + \\sigma_Y F_n(Y)\n",
    "\\end{align}\n",
    "where F_n(Y) is the empirical distribution of $Y$ in the orignal data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {
    "id": "Msy1rHY6fMoU"
   },
   "source": [
    "## Packaging the Semi-Synthetic Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from joblib import Parallel, delayed\n",
    "from proximalde.proximal import ProximalDE, residualizeW, svd_critical_value\n",
    "from proximalde.utilities import covariance\n",
    "from proximalde.gen_data import gen_data_with_mediator_violations, gen_data_no_controls_discrete_m, gen_data_no_controls, gen_data_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "d = .0  # this can be zero; does not hurt\n",
    "e = 1.0  # if the product of e*f is small, then we have a weak instrument\n",
    "f = 1.0  # if the product of e*f is small, then we have a weak instrument\n",
    "g = .0  # this can be zero; does not hurt\n",
    "\n",
    "n = 100000\n",
    "pw = 10\n",
    "pz, px = 4, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(124)\n",
    "# W, D, _, Z, X, Y = gen_data_with_mediator_violations(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "# W = None\n",
    "\n",
    "# W, D, _, Z, X, Y = gen_data_complex(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "\n",
    "## for no controls un-comment this\n",
    "# _, D, _, Z, X, Y = gen_data_no_controls(n, pw, pz, px, a, b, c, d, e, f, g)\n",
    "# W = None\n",
    "\n",
    "## for multi-dimensional mediator uncomment this\n",
    "pm = 2\n",
    "full_rank = False\n",
    "while not full_rank:\n",
    "    E = np.random.normal(0, 2, (pm, pz))\n",
    "    F = np.random.normal(0, 2, (pm, px))\n",
    "    if (np.linalg.matrix_rank(E, tol=0.5) == pm) and (np.linalg.matrix_rank(F, tol=0.5) == pm):\n",
    "        full_rank = True\n",
    "W, D, _, Z, X, Y = gen_data_no_controls_discrete_m(n, pw, pz, px, a, b, c, d, e*E, f*F, g, pm=pm)\n",
    "W = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1726019755909,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "xq0f9gwkkBUz",
    "outputId": "085d37c2-c085-4c7d-ae69-4ba76f68e441"
   },
   "outputs": [],
   "source": [
    "from proximalde.gen_data import SemiSyntheticGenerator\n",
    "\n",
    "a = 1.0  # a*b is the indirect effect through mediator\n",
    "b = 1.0\n",
    "c = .5  # this is the direct effect we want to estimate\n",
    "g = .0  # this can be zero; does not hurt\n",
    "sm = 2.0  # strength of mediator noise; needs to be non-zero for identifiability; only used when pm=1.\n",
    "nsamples = 100000\n",
    "\n",
    "generator = SemiSyntheticGenerator(split=True)\n",
    "generator.fit(W, D, Z, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wtilde, Dtilde, _, Ztilde, Xtilde, Ytilde = generator.sample(nsamples, a, b, c, g, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance(Z, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance(Z, Z), covariance(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance(Ztilde, Xtilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance(Ztilde, Ztilde), covariance(Xtilde, Xtilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Ztilde[:, 0], label='sampled')\n",
    "plt.hist(Z[:, 0], label='true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as stm\n",
    "def exp_res(it, generator, n, a, b, c, g, *, sy=1.0, n_jobs=-1, verbose=0):\n",
    "    np.random.seed(it)\n",
    "\n",
    "    # M is unobserved so we omit it from the return variables\n",
    "    W, D, M, Z, X, Y = generator.sample(n, a, b, c, g, sy=sy, replace=True)\n",
    "\n",
    "    res = stm.OLS(Y, np.hstack([D.reshape(-1, 1), M, X, np.ones((D.shape[0], 1))])).fit(cov_type='HC1')\n",
    "    return res.params[0], np.sqrt(res.cov_params()[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_res(5, generator, nsamples, a, b, c, g, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1, verbose=3)(delayed(exp_res)(i, generator, nsamples,\n",
    "                                                          a, b, c, g, n_jobs=1)\n",
    "                                          for i in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, stderrs = map(np.array, zip(*results))\n",
    "\n",
    "print(\"Estimation Quality\")\n",
    "coverage = np.mean((points + 1.96 * stderrs >= c) & (points - 1.96 * stderrs <= c))\n",
    "rmse = np.sqrt(np.mean((points - c)**2))\n",
    "bias = np.abs(np.mean(points) - c)\n",
    "std = np.std(points)\n",
    "mean_stderr = np.mean(stderrs)\n",
    "mean_length = np.mean(2 * 1.96 * stderrs)\n",
    "median_length = np.median(2 * 1.96 * stderrs)\n",
    "print(f\"Coverage: {coverage:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"Bias: {bias:.3f}\")\n",
    "print(f\"Std: {std:.3f}\")\n",
    "print(f\"Mean CI length: {mean_length:.3f}\")\n",
    "print(f\"Median CI length: {mean_length:.3f}\")\n",
    "print(f\"Mean Estimated Stderr: {mean_stderr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1726019756920,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "FxzsskIclpoh",
    "outputId": "0061e9f0-48c9-4b7b-d0e1-41852628b177"
   },
   "outputs": [],
   "source": [
    "Wtilde, Dtilde, _, Ztilde, Xtilde, Ytilde = generator.sample(nsamples, a, b, c, g, replace=True)\n",
    "\n",
    "# we find that the dual violation still exists, causing a slight bias (the true\n",
    "# value we should recover is c)\n",
    "est = ProximalDE(cv=3, semi=True, n_jobs=-1, random_state=3, verbose=3)\n",
    "est.fit(Wtilde, Dtilde, Ztilde, Xtilde, Ytilde)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1726019762625,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "HK9XULD-wTAt"
   },
   "outputs": [],
   "source": [
    "def exp_res(it, generator, n, a, b, c, g, *, sy=1.0,\n",
    "            dual_type='Z', ivreg_type='adv', n_splits=3, semi=True,\n",
    "            n_jobs=-1, verbose=0):\n",
    "    np.random.seed(it)\n",
    "\n",
    "    # M is unobserved so we omit it from the return variables\n",
    "    W, D, _, Z, X, Y = generator.sample(n, a, b, c, g, sy=sy, replace=True)\n",
    "\n",
    "    est = ProximalDE(cv=n_splits, semi=semi,\n",
    "                     dual_type=dual_type, ivreg_type=ivreg_type,\n",
    "                     n_jobs=n_jobs, random_state=it, verbose=verbose)\n",
    "    est.fit(W, D, Z, X, Y)\n",
    "    weakiv_stat, _, _, weakiv_crit = est.weakiv_test(alpha=0.05)\n",
    "    idstr, _, _, idstr_crit = est.idstrength_violation_test(alpha=0.05)\n",
    "    pval, _, _, pval_crit = est.primal_violation_test(alpha=0.05)\n",
    "    dval, _, _, dval_crit = est.dual_violation_test(alpha=0.05)\n",
    "    lb, ub = est.robust_conf_int(lb=-2, ub=2)\n",
    "    return est.point_, est.stderr_, est.r2D_, est.r2Z_, est.r2X_, est.r2Y_, \\\n",
    "        idstr, idstr_crit, est.point_pre_, est.stderr_pre_, \\\n",
    "        pval, pval_crit, dval, dval_crit, weakiv_stat, weakiv_crit, \\\n",
    "        lb, ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3820,
     "status": "ok",
     "timestamp": 1726019766814,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "PF4tZpZ1uIJp",
    "outputId": "d5048391-9701-435d-c769-ecbe8f4a24e4"
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1, verbose=3)(delayed(exp_res)(i, generator, nsamples,\n",
    "                                                          a, b, c, g,\n",
    "                                                          dual_type='Z', ivreg_type='adv',\n",
    "                                                          n_splits=3, semi=True, n_jobs=1)\n",
    "                                          for i in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1726019766814,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "tRdBUIxW0XQ1",
    "outputId": "858ecc04-3d9c-4ae7-8df2-7b76b51c04ea"
   },
   "outputs": [],
   "source": [
    "points_base, stderrs_base, rmseD, rmseZ, rmseX, rmseY, \\\n",
    "    idstr, idstr_crit, points_alt, stderrs_alt, \\\n",
    "    pval, pval_crit, dval, dval_crit, wiv_stat, wiv_crit, \\\n",
    "    rlb, rub = map(np.array, zip(*results))\n",
    "\n",
    "points_base = np.array(points_base)\n",
    "stderrs_base = np.array(stderrs_base)\n",
    "points_alt = np.array(points_alt)\n",
    "stderrs_alt = np.array(stderrs_alt)\n",
    "\n",
    "print(\"Estimation Quality\")\n",
    "for name, points, stderrs in [('Debiased', points_base, stderrs_base), ('Regularized', points_alt, stderrs_alt)]:\n",
    "    print(f\"\\n{name} Estimate\")\n",
    "    coverage = np.mean((points + 1.96 * stderrs >= c) & (points - 1.96 * stderrs <= c))\n",
    "    rmse = np.sqrt(np.mean((points - c)**2))\n",
    "    bias = np.abs(np.mean(points) - c)\n",
    "    std = np.std(points)\n",
    "    mean_stderr = np.mean(stderrs)\n",
    "    mean_length = np.mean(2 * 1.96 * stderrs)\n",
    "    median_length = np.median(2 * 1.96 * stderrs)\n",
    "    print(f\"Coverage: {coverage:.3f}\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"Bias: {bias:.3f}\")\n",
    "    print(f\"Std: {std:.3f}\")\n",
    "    print(f\"Mean CI length: {mean_length:.3f}\")\n",
    "    print(f\"Median CI length: {mean_length:.3f}\")\n",
    "    print(f\"Mean Estimated Stderr: {mean_stderr:.3f}\")\n",
    "    print(f\"Nuisance R^2 (D, Z, X, Y): {np.mean(rmseD):.3f}, {np.mean(rmseZ):.3f}, {np.mean(rmseX):.3f}, {np.mean(rmseY):.3f}\")\n",
    "\n",
    "print(\"\\nRobust ConfInt Coverage\")\n",
    "rcoverage = np.mean((rub >= c) & (rlb <= c))\n",
    "print(f\"Robust Coverage: {rcoverage:.3f}\")\n",
    "\n",
    "print(\"\\nViolations\")\n",
    "for name, stat, crit in [('Id-Strenth', idstr, idstr_crit), ('WeakIV F-test', wiv_stat, wiv_crit)]:\n",
    "    violation = np.mean(stat <= crit)\n",
    "    print(f\"% Violations of {name}: {violation:.3f}\")\n",
    "for name, stat, crit in [('Primal Existence', pval, pval_crit), ('Dual Existence', dval, dval_crit)]:\n",
    "    violation = np.mean(stat >= crit)\n",
    "    print(f\"% Violations of {name}: {violation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {
    "id": "2sffn7TE0d5L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "T6FelHd78d8T",
    "57abc1f7-1569-469d-8239-12fce056e875",
    "a482021b-9c5b-4123-b20c-878b2940ee33",
    "M0Zp1JDoZBbi"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "11wI4lKMKFJmVN9v4WAK15TtifoY686Vb",
     "timestamp": 1726017290265
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
