{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "T6FelHd78d8T"
   },
   "source": [
    "# Main Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1725304888843,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "a1446bbd-c4be-4846-b09a-e36fad2802ab",
    "outputId": "1da66a3a-0830-4d54-dea1-3e05fdadb7a0"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1725304889203,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "c79a60f7-dde3-4c7c-8419-ce831b20e824"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from proximalde.ukbb_data_utils import load_ukbb_data\n",
    "from proximalde.ukbb_proximal import ProximalDE_UKBB\n",
    "from proximalde.proximal import ProximalDE\n",
    "pd.options.display.max_columns = None\n",
    "from tqdm import tqdm \n",
    "import os \n",
    "import pickle as pk\n",
    "from proximalde.ukbb_data_utils import *\n",
    "\n",
    "SAVE_PATH = './results/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "dfs = []\n",
    "D_labels = ['Black', 'Female', 'Obese', 'Asian', 'On_dis', \"No_uni\", 'Low_inc', 'No_priv_insr']\n",
    "Y_labels = ['OA', 'myoc','deprs', 'back', 'RA', 'fibro', 'infl', 'copd','chrkd','mgrn','mela', 'preg', 'endo']\n",
    "for D_label in D_labels:\n",
    "    for Y_label in Y_labels:\n",
    "        dir = f'./results/D={D_label}_Y={Y_label}/Dbin=False_Ybin=False_XZbin=False_Rgr=linear/'\n",
    "        if not os.path.exists(dir + '/table2.csv'):\n",
    "            continue\n",
    "        else:\n",
    "            test_df = pd.read_csv(dir + '/table2.csv',header=1, index_col=1)\n",
    "            point_df = pd.read_csv(dir + '/table0.csv',header=1, index_col=1)\n",
    "            point_df['ci'] = point_df.stderr * 1.96\n",
    "            test_df['stat,crit'] = test_df.apply(lambda x: f\"{round(x.statistic,1)},{round(x['critical value'],1)}\", axis=1)\n",
    "            test_df = test_df[['stat,crit']]\n",
    "            test_df.index=['id','primal','dual', 'weakIV']\n",
    "            test_df_flat = test_df.T.unstack().to_frame().sort_index(level=1).T\n",
    "            test_df_flat.columns = test_df_flat.columns.map('_'.join)\n",
    "            point_df = point_df[['point', 'ci']]                  \n",
    "            df = pd.concat([point_df.reset_index(), test_df_flat.reset_index()],axis=1)\n",
    "            point = df[[c for c in df.columns if c != 'index']]\n",
    "            point['dy'] = f'{D_label}_{Y_label}'\n",
    "            dfs.append(point)\n",
    "df = pd.concat(dfs)            \n",
    "def statcrit_fn(df):\n",
    "    direction = {'dual':'<', 'primal':'<', 'id':'>', 'weakIV':'>'}\n",
    "yy={'OA': 'Osteoarthritis', 'back': 'Back pain', 'deprs': 'Depression', 'myoc': \"Heart disease\", 'RA': 'Rh. Arthritis', 'fibro': 'Fibromyalgia', 'chrkd': 'Chronic kidney disease'}\n",
    "dd={'Low_inc': 'Low Income','Obese':'Obese', 'Female': 'Female', 'Black': 'Black', 'Asian': \"Asian\", 'On_dis': 'Disability insurance'}\n",
    "df['D_Y'] = df.dy.map(lambda x: dd['_'.join(x.split('_')[:-1])] + ', ' + yy[x.split('_')[-1]])\n",
    "df['dual_stat,crit'] = df['dual_stat,crit'].map(lambda x: f\"{round(float(x.split(',')[0]),1)}<{round(float(x.split(',')[-1]),1)}\")\n",
    "df['primal_stat,crit'] = df['primal_stat,crit'].map(lambda x: f\"{round(float(x.split(',')[0]),1)}<{round(float(x.split(',')[-1]),1)}\")\n",
    "df['id_stat,crit'] = df['id_stat,crit'].map(lambda x: f\"{round(float(x.split(',')[0]),1)}>{round(float(x.split(',')[-1]),1)}\")\n",
    "df['weakIV_stat,crit'] = df['weakIV_stat,crit'].map(lambda x: f\"{round(float(x.split(',')[0]),1)}>{round(float(x.split(',')[-1]),1)}\")\n",
    "df.point = [f'{round(x,2)}$\\pm${round(y,2)}' for x,y in zip(df.point,df.ci)]\n",
    "df =df[['D_Y', 'point','primal_stat,crit', 'dual_stat,crit', 'id_stat,crit', 'weakIV_stat,crit']]\n",
    "df.to_csv('all_norm_7metrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "all_data = {}\n",
    "D_labels = ['Black', 'Female', 'Obese', 'Asian', 'On_dis', \"No_uni\", 'Low_inc', 'No_priv_insr']\n",
    "Y_labels = ['OA', 'myoc','deprs', 'back', 'RA', 'fibro', 'infl', 'copd','chrkd','mgrn','mela', 'preg', 'endo']\n",
    "for D_label in D_labels:\n",
    "    for Y_label in Y_labels:\n",
    "        dir = f'./results/D={D_label}_Y={Y_label}/Dbin=False_Ybin=False_XZbin=False_Rgr=linear/'\n",
    "        if not os.path.exists(dir + '/table2.csv'):\n",
    "            continue\n",
    "        else:\n",
    "            print(dir + ' exists')\n",
    "            og_test = pd.read_csv(dir + '/table2.csv')\n",
    "            og_point = pd.read_csv(dir + '/table0.csv')\n",
    "        \n",
    "#         candidates = pk.load(open(f'./{D_label}_{Y_label}_candidates_reweight_acually.pkl', 'rb'))\n",
    "#         new_tests = []\n",
    "#         new_points = []\n",
    "#         saved_cand=[]\n",
    "#         for idx in np.arange(len(candidates)):\n",
    "#             try:\n",
    "#                 fname = f'./results/proxyrm/{D_label}_{Y_label}_{idx}_random/'\n",
    "#                 point = pd.read_csv(f'{fname}/table0.csv', header=1, index_col=1)\n",
    "#                 test = pd.read_csv(f'{fname}/table2csv', header=1, index_col=1)\n",
    "#                 if test['pass test'].sum() > 2:\n",
    "#                     new_tests.append(test)\n",
    "#                     new_points.append(point)\n",
    "#                     saved_cand.append((Xset, Zset))\n",
    "#             except FileNotFoundError:\n",
    "#                 pass\n",
    "#         if len(new_tests) > 0:\n",
    "#             all_data[f'{D_label}_Y={Y_label}'] = {'tests': [og_test]+all_tests, 'point': [og_point] + new_points, 'cand': saved_cand}\n",
    "#             print(f'{D_label}_Y={Y_label}', len(new_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for regr, clsf, D_label, Y_label, Dbin, Ybin, XZbin in product(['linear', 'xgb'], ['xgb'], \n",
    "                                            ['Black', 'Female', 'Obese', 'Asian'], \n",
    "                                            ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back'],\n",
    "                                           [True, False],\n",
    "                                           [True,False],\n",
    "                                           [True,False]):\n",
    "        try:\n",
    "            if np.array([Dbin,Ybin,XZbin]).any():\n",
    "                clsf = f'_Cls={clsf}'\n",
    "            else:\n",
    "                clsf = ''\n",
    "            save_dir = f'{SAVE_PATH}/D={D_label}_Y={Y_label}/Dbin={Dbin}_Ybin={Ybin}_XZbin={XZbin}_Rgr={regr}{clsf}'\n",
    "            \n",
    "            W, _, W_feats, X, X_binary, X_feats, Z, Z_binary, Z_feats, Y, D = load_ukbb_data(D_label=D_label, Y_label=Y_label)\n",
    "        \n",
    "            print(save_dir)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.mkdir(save_dir)\n",
    "            if not os.path.exists(save_dir + '/table1.csv'):\n",
    "                np.random.seed(4)\n",
    "                est = ProximalDE_UKBB(model_regression=regr, \n",
    "                                      model_classification='xgb',\n",
    "                                      binary_D=Dbin, binary_Y=Ybin,\n",
    "                                      binary_X=X_binary if XZbin else [], binary_Z=Z_binary if XZbin else [], \n",
    "                                      semi=True, cv=3, verbose=1, random_state=3)\n",
    "\n",
    "                est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label, save_fname_addn='')                \n",
    "                sm = est.summary(decimals=5, save_dir=save_dir)\n",
    "                print(sm.tables[0])\n",
    "                print(sm.tables[1])\n",
    "                print(sm.tables[2])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "#             if Y_label == 'OA':\n",
    "#                 svalues, svalues_crit = est.covariance_rank_test(calculate_critical=True)\n",
    "#                 np.save(save_dir + '/covrank_test.npy', np.concatenate([svalues, [svalues_crit]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Analyze results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Load all data into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "from itertools import product\n",
    "\n",
    "for regr, clsf, D_label, Y_label, Dbin, Ybin, XZbin in product(['linear', 'xgb'], ['linear', 'xgb'], \n",
    "                                            ['Black', 'Female', 'Obese', 'Asian'], \n",
    "                                            ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back'],\n",
    "                                           [True, False],\n",
    "                                           [True, False],\n",
    "                                           [True,False]):\n",
    "        try:\n",
    "            if np.array([Dbin,Ybin,XZbin]).any():\n",
    "                clsf = f'_Cls={clsf}'\n",
    "            else:\n",
    "                clsf = ''\n",
    "            save_dir = f'{SAVE_PATH}/D={D_label}_Y={Y_label}/Dbin={Dbin}_Ybin={Ybin}_XZbin={XZbin}_Rgr={regr}{clsf}'\n",
    "            test_df = pd.read_csv(save_dir + '/table2.csv', header=1, index_col=1)\n",
    "            test_df = test_df.drop(columns=['0'])\n",
    "            test_df_flat = test_df.T.unstack().to_frame().sort_index(level=1).T\n",
    "            test_df_flat.columns = test_df_flat.columns.map('_'.join)\n",
    "            point_df = pd.read_csv(save_dir + '/table0.csv', header=1, index_col=1)\n",
    "            point_df = point_df.drop(columns=['0'])                    \n",
    "            res_df = pd.read_csv(save_dir + '/table1.csv', header=1, index_col=1)\n",
    "            res_df = res_df.drop(columns=['0'])\n",
    "            df = pd.concat([point_df.reset_index(), test_df_flat.reset_index(), res_df.reset_index()],axis=1)\n",
    "            df = df[[c for c in df.columns if c != 'index']]\n",
    "            df['D_Y'] = f'{D_label}_{Y_label}'\n",
    "            df['hparams'] = f'Dbin={Dbin}_Ybin={Ybin}_XZbin={XZbin}_Rgr={regr}{clsf}'\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "df = pd.concat(dfs,axis=0)\n",
    "# res_df = pd.concat(res_dfs)\n",
    "# test_df = pd.concat(test_dfs)\n",
    "# test_df = test_df.reindex(sorted(test_df.columns), axis=1)\n",
    "# point_df.to_csv('./results/all_point_est.csv')\n",
    "# test_df.to_csv('./results/all_tests.csv')\n",
    "# res_df.to_csv('./results/all_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "ss_DY = df[(np.sign(df.ci_lower) == np.sign(df.ci_upper)) & (np.abs(df.point) > .05)].D_Y.unique()\n",
    "df = df[df.D_Y.isin(ss_DY)]\n",
    "point_df[(np.sign(point_df.ci_lower) == np.sign(point_df.ci_upper)) & (np.abs(point_df.point)>.05)]\n",
    "for y in ['point', 'stderr'] + [c for c in df.columns if ('statistic' in c) | ('critical' in c) | ('r2' in c)]:\n",
    "    plt.subplots(figsize=(30,6))\n",
    "    sns.barplot(data=df, hue='hparams', x='D_Y',y=y)\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"Comparing {y}\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_DY = point_df[(np.sign(point_df.ci_lower) == np.sign(point_df.ci_upper)) & (np.abs(point_df.point)>.05)].D_Y.unique()\n",
    "point_df[(np.sign(point_df.ci_lower) == np.sign(point_df.ci_upper)) & (np.abs(point_df.point)>.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reindex(sorted(test_df.columns), axis=1)\n",
    "test_df[test_df.D_Y.isin(ss_DY)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Visualize rank test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for D_label in ['Black', 'Female', 'Obese','Asian']:\n",
    "    print(D_label)\n",
    "    for Y_label in ['OA']:\n",
    "        covrank_data = np.load(f'{SAVE_PATH}/ivreg=adv_dual=Z_D={D_label}_Y={Y_label}/covrank_test.npy')\n",
    "        svalues, svalues_crit = covrank_data[:-1], covrank_data[-1]\n",
    "        plt.title(f\"D={D_label}_Y={Y_label}\\nNumber of singular values above threshold: {np.sum(svalues >= svalues_crit)}. \"\n",
    "                  f\"\\nThreshold={svalues_crit:.3f}. Top singular value={svalues[0]:.3f}\")\n",
    "        plt.scatter(np.arange(len(svalues)), svalues)\n",
    "        plt.axhline(svalues_crit)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Other diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1725302413079,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "d566ecd4-2574-4f72-a5d2-c9d2e645ad5c"
   },
   "outputs": [],
   "source": [
    "refit_rm_inf = False \n",
    "for D_Y in ss_DY:\n",
    "    D_label, Y_label = D_Y.split('_')\n",
    "    W, W_feats, X, X_feats, Z, Z_feats, Y, D = load_ukbb_data(D_label=D_label, Y_label=Y_label)\n",
    "    save_dir = f'{SAVE_PATH}/ivreg={ivreg_type}_dual={dual_type}_D={D_label}_Y={Y_label}'\n",
    "    print(save_dir)\n",
    "    np.random.seed(4)\n",
    "    est = ProximalDE_UKBB(cv=3, semi=True, dual_type=dual_type, ivreg_type=ivreg_type,\n",
    "                         multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "    est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label)    \n",
    "    diag = est.run_diagnostics()\n",
    "    inds = est.influential_set(alpha=0.05)\n",
    "    print(len(inds))\n",
    "    diag.cookd_plot()\n",
    "    plt.title(save_dir)\n",
    "    plt.show()\n",
    "    diag.l2influence_plot()\n",
    "    plt.title(save_dir)\n",
    "    plt.show()\n",
    "    diag.influence_plot(influence_measure='cook', npoints=10)\n",
    "    plt.title(save_dir)\n",
    "    plt.show()\n",
    "    \n",
    "    if refit_rm_inf == True:\n",
    "        from sklearn.base import clone\n",
    "        np.random.seed(4)\n",
    "        est2 = clone(est)\n",
    "        est2.fit(np.delete(W, inds, axis=0), np.delete(D, inds, axis=0),\n",
    "                 np.delete(Z, inds, axis=0), np.delete(X, inds, axis=0),\n",
    "                 np.delete(Y, inds, axis=0),D_label=D_label, Y_label=Y_label, save_fname_addn=f'_rmInf{dual_type}')\n",
    "        est2.summary(alpha=0.05)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "nemTbAS4FZQw"
   },
   "outputs": [],
   "source": [
    "from proximalde.ukbb_data_utils import *\n",
    "# UKBB_DATA_DIR = '/oak/stanford/groups/rbaltman/karaliu/bias_detection/cohort_creation/data/'\n",
    "    \n",
    "# potD_fids = np.load(f'{UKBB_DATA_DIR}/potD_feats.npy')\n",
    "# potD_intfids = list(get_int_feats(np.load(f'{UKBB_DATA_DIR}/potD_feats.npy')[:-4])) + ['Race=Asian','Race=Black']\n",
    "potD_binary = [True]*len(potD_intfids)\n",
    "\n",
    "# Wfeats = get_int_feats(np.load(f'{UKBB_DATA_DIR}/dem_feats_rd.npy'))\n",
    "Wbinary_=is_matrix_binary(np.load(f'{UKBB_DATA_DIR}/dem_data_rd.npy'))\n",
    "# Wfeats = np.concatenate([Wfeats,potD_intfids])\n",
    "Wbinary = np.concatenate([Wbinary_,potD_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proximalde.ukbb_data_utils import _load_ukbb_data\n",
    "def gen_feat_csv_for_paper(isbinary,fids=None, intfids=None,rm_na=False):\n",
    "    if intfids is None:\n",
    "        intfids =get_int_feats(fids)\n",
    "    if rm_na:\n",
    "        bad_idx = np.array([('Do not know' in x) or ('Prefer not to' in x) for x in intfids])\n",
    "        intfids, isbinary = intfids[~bad_idx], isbinary[~bad_idx]\n",
    "    return pd.DataFrame({'full_feat':intfids, 'feat':[x.split('=')[0] for x in intfids], 'var':['Categorical' if x else 'Continuous' for x in isbinary]})\n",
    "\n",
    "# Z, Z_binary, Z_feats = _load_ukbb_data(fname = 'srMntSlp')\n",
    "# X, X_binary, X_feats = _load_ukbb_data(fname = 'biomMed')\n",
    "# df = gen_feat_csv_for_paper(fids=Z_feats,isbinary=Z_binary,rm_na=True)\n",
    "# df.groupby(['feat', 'var']).size().reset_index(name='count').to_csv('Zcsv.csv')\n",
    "# df = gen_feat_csv_for_paper(fids=X_feats,isbinary=X_binary,rm_na=True)\n",
    "# df.groupby(['feat', 'var']).size().reset_index(name='count').to_csv('Xcsv.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_feat_csv_for_paper(intfids=Wfeats,isbinary=Wbinary,rm_na=False)\n",
    "df = df.groupby(['feat', 'var']).size().reset_index(name='count')\n",
    "df.to_csv('Wcsv.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
