{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "T6FelHd78d8T"
   },
   "source": [
    "# Empirical weak proxy analysis on UKBB data \n",
    "\n",
    "Method to identify potentially weak proxies X and Z that violate the dual and primal equations. \n",
    "For the following explanation, assume we are looking at the dual equation $E[X(D-\\gamma'Z)]$. \n",
    "\n",
    "1. Compute the $Cov(DX)$. Non-zero covariance is identified by asserting the pearson correlation p-value between some feature $X_i$ and $D$ > $.05/dx.$ We only consider these $X_i \\in X_{ss}$ features henceforth. \n",
    "\n",
    "\n",
    "2. Compute $Cov(XZ)$. From here we can identify potentially weak $X$ and $Z$.\n",
    "    1. To identify weak $X$, we look at all $X_i \\in X_{ss}$, and if there are no $Z$ features with non-zero covariance (determined by pearson p-value again) with $X_i$, we identify $X_i$ as a weak proxy. \n",
    "    2. Note we want the minimal subset of $Z$ such that its covariance with $X$ still span $Cov(DX)$. To do so, we pick the $Z$s that have the most associations with the $X_i \\in  X_{ss}$. Let $Cov(XZ)_{ss}$ denote the binary $dx$ by $dz$ matrix where 1 denotes the Z and X feat had a p-value < .05/dx * dz. We have a hyperparameter $N$ (or `popular_z_thresh`) that denotes, in the case of $Cov(X_{ss}Z)_{ss}$, the column sum of how many $X_i \\in  X_{ss}$ each $Z$ has association with. We take only the $Z$ feats that have > $N$ associations.\n",
    "    \n",
    "\n",
    "We repeat this for the primal, flipping D <-> Y and Z <-> X. The final X,Z features kept must pass both the identification tests for both the primal and dual. Varying $N$ controls how rigid we are. \n",
    "\n",
    "Note: I did not account for all the replications of these tests, at least # D_Y * 2 (dual + primal), so p-value correction might need to be adjusted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1725304888843,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "a1446bbd-c4be-4846-b09a-e36fad2802ab",
    "outputId": "1da66a3a-0830-4d54-dea1-3e05fdadb7a0"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1725304889203,
     "user": {
      "displayName": "Vasilis Syrganis",
      "userId": "00968929417250286436"
     },
     "user_tz": 420
    },
    "id": "c79a60f7-dde3-4c7c-8419-ce831b20e824"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from proximalde.ukbb_proximal import ProximalDE_UKBB\n",
    "from proximalde.ukbb_data_utils import *\n",
    "import seaborn as sns \n",
    "pd.options.display.max_columns = None\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Tools for loading data and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import textwrap \n",
    "def wrap_labels(labels, max_characters):\n",
    "    return [textwrap.fill(label, max_characters) for label in labels]\n",
    "\n",
    "def get_cov(x, y, get_pvals=False):\n",
    "    \"\"\"\n",
    "    Returns covariance matrix between the columns of x and y.\n",
    "    If get_pvals, also returns the pvals associated with a pearson \n",
    "    correlation, and the pval threshold of significance = .05 / dy * dx\n",
    "    \"\"\"\n",
    "    xc = x - np.mean(x, axis=0)\n",
    "    yc = y - np.mean(y, axis=0)\n",
    "    cov = np.dot(xc.T, yc) / (xc.shape[0] - 1)\n",
    "    \n",
    "    if get_pvals:\n",
    "        dx, dy = xc.shape[1], yc.shape[1]\n",
    "        std_x = np.std(xc, axis=0, ddof=1)\n",
    "        std_y = np.std(yc, axis=0, ddof=1)\n",
    "        corr_matrix = cov / np.outer(std_x, std_y)\n",
    "        \n",
    "        dof = xc.shape[0] - 2\n",
    "        t_stat = corr_matrix * np.sqrt(dof / (1 - corr_matrix**2))\n",
    "        pvals = 2 * t.sf(np.abs(t_stat), dof)\n",
    "        pvals[np.isnan(pvals)] = 1 #replace NaNs\n",
    "        \n",
    "        return cov, pvals, .05 / (dx * dy)\n",
    "    else:\n",
    "        return cov\n",
    "    \n",
    "UKBB_DATA_DIR = '/oak/stanford/groups/rbaltman/karaliu/bias_detection/cohort_creation/data/'\n",
    "\n",
    "def _load_data(fname: str):\n",
    "    data = np.load(UKBB_DATA_DIR + f'{fname}_data_rd.npy', allow_pickle=False)    \n",
    "    feats = np.load(UKBB_DATA_DIR + f'{fname}_feats_rd.npy', allow_pickle=False)\n",
    "    assert np.isnan(data).sum() == 0, 'NaN values cannot exist in data'\n",
    "    return data, feats\n",
    "    \n",
    "def load_XZ_data():\n",
    "    Z, Z_feats = _load_data(fname = 'srMntSlp')\n",
    "    X, X_feats = _load_data(fname = 'biomMed')\n",
    "    return X, X_feats, Z, Z_feats\n",
    "\n",
    "def load_DY_data(D_label, Y_label):\n",
    "    D_df = pd.read_csv(UKBB_DATA_DIR + 'updated_sa_df_pp.csv')\n",
    "    D = D_df[D_label].to_numpy()     \n",
    "    Y = pd.read_csv(UKBB_DATA_DIR + 'updated_Y_labels.csv')[Y_label].to_numpy()[:,None] \n",
    "    return D, Y\n",
    "\n",
    "def load_res_data(D_label, Y_label):\n",
    "    _get_path = lambda fname: f'/oak/stanford/groups/rbaltman/karaliu/bias_detection/causal_analysis/data_hm/{fname}'\n",
    "    D_label = D_label.replace('_', '')\n",
    "    Winfo = f'_Wrm{D_label}'\n",
    "    Yres = np.load(_get_path(f'Yres_{Y_label}{Winfo}.npy')) \n",
    "    Dres = np.load(_get_path(f'Dres_{D_label}.npy')) \n",
    "    Xres = np.load(_get_path(f'Xres{Winfo}.npy')) \n",
    "    Zres = np.load(_get_path(f'Zres{Winfo}.npy')) \n",
    "    return Xres, Zres, Yres, Dres\n",
    "\n",
    "def XZ_hparam_plot(dual_or_primal='dual'):\n",
    "    \"\"\"\n",
    "    Tool for visualizing covariance matrices \n",
    "    and how different thresholds for N affect the corresponding covariance.\n",
    "    Could be for dual or primal. \n",
    "    \"\"\"\n",
    "    \n",
    "    D_labels = ['Female', 'Obese','Black', 'Asian']\n",
    "    if dual_or_primal=='dual':\n",
    "        Y_labels = ['OA']\n",
    "    else:\n",
    "        Y_labels = ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']\n",
    "    for D_label in D_labels:\n",
    "        print(D_label)\n",
    "        for Y_label in Y_labels:\n",
    "            Xres, Zres, _, Dres = load_res_data(D_label, Y_label=Y_label)\n",
    "            if dual_or_primal=='dual':\n",
    "                Xrpr, Zrpr, Drpr, label = 'X', 'Z', 'D', D_label\n",
    "                XZres_cov, XZres_pvals, XZres_thresh = get_cov(Xres, Zres, get_pvals=True)\n",
    "                DXres_cov, DXres_pvals, DXres_thresh = get_cov(Dres, Xres, get_pvals=True)\n",
    "            else:\n",
    "                Xrpr, Zrpr, Drpr, label = 'Z', 'X', 'Y', Y_label\n",
    "                XZres_cov, XZres_pvals, XZres_thresh = get_cov(Zres, Xres, get_pvals=True)\n",
    "                DXres_cov, DXres_pvals, DXres_thresh = get_cov(Yres, Zres, get_pvals=True)\n",
    "            \n",
    "            # We only care about X feats with st.sig. assn with D\n",
    "            ss_DXidx = (DXres_pvals < DXres_thresh).squeeze()\n",
    "            if dual_or_primal=='dual':\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(20, 5), dpi=70)\n",
    "            else:\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 5), dpi=70)\n",
    "\n",
    "            im = axs[0].imshow((XZres_pvals[ss_DXidx] < XZres_thresh), aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "            axs[0].set_title(f\"Nonzero Covariance({Xrpr},{Zrpr})\\n(if spearman pvalue < .05/dz*dx)\", fontsize=12)\n",
    "            axs[0].set_ylabel(f\"{Xrpr} feats\", fontsize=10)\n",
    "            axs[0].set_xlabel(f\"{Zrpr} feats\", fontsize=10)\n",
    "            cbar = fig.colorbar(im, ax=axs[0], orientation='vertical')\n",
    "            cbar.set_ticks([0, 1])\n",
    "            cbar.set_ticklabels(['Zero', 'Nonzero'])\n",
    "\n",
    "            \n",
    "            nZfeats = []\n",
    "            Xfeats_w_zero_Zfeats = []\n",
    "            for i in range(40):\n",
    "                keep = (XZres_pvals[ss_DXidx] < XZres_thresh).sum(axis=0) > i\n",
    "                zero = ((XZres_pvals[ss_DXidx][:, keep] < XZres_thresh).sum(axis=1) == 0).sum()\n",
    "                nZfeats.append(keep.sum())\n",
    "                Xfeats_w_zero_Zfeats.append(zero)\n",
    "                \n",
    "            axs[1].set_title(f\"Each {Zrpr} feat's # st.sig. correlations w/ all {Xrpr} feats, {Drpr}={label}\", fontsize=12)\n",
    "            ax3 = axs[1]\n",
    "            ax3.plot(range(40), nZfeats, color='blue')\n",
    "            ax3.set_ylabel(f\"# {Zrpr} feats correlated with >N {Xrpr} feats\", color='blue')\n",
    "            ax3.set_xlabel(f\"N\\n(hparam for filtering {Xrpr} feats)\")\n",
    "            ax3.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "            ax3b = ax3.twinx()\n",
    "            ax3b.plot(range(40), Xfeats_w_zero_Zfeats, color='green')\n",
    "            ax3b.set_ylabel(f\"# {Xrpr} feats w/ 0 st.sig. feat correlation\\nafter rm {Zrpr} feats correlated with <N {Xrpr} feats\", color='green')\n",
    "            ax3b.tick_params(axis='y')\n",
    "\n",
    "            ax3.set_title(f'How removing {Zrpr} feats affects Cov(X,Z)')\n",
    "            ax3.grid(True, axis='y', linestyle='--', linewidth=0.5, color='lightgray')\n",
    "\n",
    "            # Adjust layout to prevent overlapping\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f\"{dual_or_primal} violation plots for {Drpr}={label}\\nusing Xres, Zres\")\n",
    "            # Show the combined plots\n",
    "            plt.show()\n",
    "\n",
    "def XZ_vis_cov(rmX_zeroZ_dual, popssZ_dual, rmZ_zeroX_primal, popssX_primal):\n",
    "\n",
    "\n",
    "    for D_label in ['Female', 'Obese','Black', 'Asian']:\n",
    "        for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "            print(f\"{D_label}->{Y_label}\")\n",
    "            W, W_feats, X, X_feats, Z, Z_feats, Y, D = load_ukbb_data(D_label=D_label, Y_label=Y_label)\n",
    "            Xres, Zres, Yres, Dres = load_res_data(D_label, Y_label)\n",
    "\n",
    "            # Filter X,Z based on bad proxies proxies \n",
    "            Xprm_idx = popssX_primal[Y_label][D_label]    \n",
    "            Zprm_idx = ~rmZ_zeroX_primal[Y_label][D_label]\n",
    "            Zdual_idx = popssZ_dual['OA'][D_label]   \n",
    "            Xdual_idx = ~rmX_zeroZ_dual['OA'][D_label]\n",
    "\n",
    "            Xres = Xres[:,(Xprm_idx & Xdual_idx)]\n",
    "            Zres = Zres[:,(Zprm_idx & Zdual_idx)]\n",
    "\n",
    "            XZres_cov, XZres_pvals, XZres_thresh = get_cov(Xres,Zres, get_pvals=True)\n",
    "            DXres_cov, DXres_pvals, DXres_thresh = get_cov(Dres, Xres, get_pvals=True)\n",
    "            YZres_cov, YZres_pvals, YZres_thresh = get_cov(Yres, Zres, get_pvals=True)\n",
    "\n",
    "            XZres_cov1 = np.concatenate([XZres_cov, YZres_cov], axis=0)\n",
    "            DXres_cov1 = np.vstack([np.array([[0]]), DXres_cov.reshape(-1, 1)])\n",
    "            XZres_cov2 = np.concatenate([XZres_cov1, DXres_cov1], axis=1)\n",
    "            plt.subplots(1,1,figsize=(12,8),dpi=60)\n",
    "            sns.heatmap(np.abs(XZres_cov2), cmap='Blues')\n",
    "            plt.axhline(y=Xres.shape[1], color='black', linewidth=2)  # Line between N and N+1 (where the vector is appended)\n",
    "            plt.axvline(x=Zres.shape[1], color='black', linewidth=2)  # Line between N and N+1 (where the vector is appended)\n",
    "            xtick_labels = list(Xint[(Xprm_idx & Xdual_idx)]) + [f'D={D_label}']  # First N are xi, last one is D\n",
    "            plt.yticks(ticks=np.arange(Xres.shape[1]+1)+.5, labels=xtick_labels, rotation=0)\n",
    "            ytick_labels = list(Zint[(Zprm_idx & Zdual_idx)]) + [f'Y={Y_label}']  # First N are xi, last one is D\n",
    "            plt.xticks(ticks=np.arange(Zres.shape[1]+1)+.5, labels=wrap_labels(ytick_labels,50),rotation=90, fontsize=8)\n",
    "            plt.xlabel('Z feats')\n",
    "            plt.ylabel('X feats')\n",
    "            plt.title(f'|Cov(X,Z)| after filtering X,Z\\n{D_label}->{Y_label}')\n",
    "            plt.show()\n",
    "\n",
    "            assert ((XZres_pvals < XZres_thresh).sum(axis=0) > 0).all()\n",
    "            assert ((XZres_pvals < XZres_thresh).sum(axis=1) > 0).all()\n",
    "            XZres_cov1 = np.concatenate([XZres_pvals < XZres_thresh, YZres_pvals < YZres_thresh], axis=0)\n",
    "            DXres_cov1 = np.vstack([np.array([[0]]), DXres_pvals.reshape(-1, 1) < DXres_thresh])\n",
    "            XZres_cov2 = np.concatenate([XZres_cov1, DXres_cov1], axis=1)\n",
    "            plt.subplots(1,1,figsize=(12,8),dpi=60)\n",
    "            sns.heatmap(np.abs(XZres_cov2), cmap='Blues')\n",
    "            plt.axhline(y=Xres.shape[1], color='black', linewidth=2)  # Line between N and N+1 (where the vector is appended)\n",
    "            plt.axvline(x=Zres.shape[1], color='black', linewidth=2)  # Line between N and N+1 (where the vector is appended)\n",
    "            xtick_labels = list(Xint[(Xprm_idx & Xdual_idx)]) + [f'D={D_label}']  # First N are xi, last one is D\n",
    "            plt.yticks(ticks=np.arange(Xres.shape[1]+1)+.5, labels=xtick_labels, rotation=0)\n",
    "            ytick_labels = list(Zint[(Zprm_idx & Zdual_idx)]) + [f'Y={Y_label}']  # First N are xi, last one is D\n",
    "            plt.xticks(ticks=np.arange(Zres.shape[1]+1)+.5, labels=wrap_labels(ytick_labels,50),rotation=90, fontsize=8)\n",
    "            plt.xlabel('Z feats')\n",
    "            plt.ylabel('X feats')\n",
    "            plt.title(f'Nonzero Cov(X,Z) after filtering X,Z\\n{D_label}->{Y_label}')\n",
    "            plt.show()\n",
    "\n",
    "            DYXres = np.concatenate([Dres, Yres, Xres], axis=1)\n",
    "            Zall_cov, Zall_pvals, Zall_thresh = get_cov(DYXres, Zres, get_pvals=True)\n",
    "            plt.subplots(1,1,figsize=(12,8),dpi=60)\n",
    "            sns.heatmap(np.abs(Zall_cov), cmap='Blues')\n",
    "            xtick_labels =[f'D={D_label}', f'Y={Y_label}'] + list(Xint[(Xprm_idx & Xdual_idx)])  # First N are xi, last one is D\n",
    "            plt.yticks(ticks=np.arange(Xres.shape[1]+2)+.5, labels=xtick_labels, rotation=0)\n",
    "            ytick_labels = list(Zint[(Zprm_idx & Zdual_idx)])\n",
    "            plt.xticks(ticks=np.arange(Zres.shape[1])+.5, labels=wrap_labels(ytick_labels,50),rotation=90, fontsize=10)\n",
    "            plt.ylabel('X feats')\n",
    "            plt.xlabel('Z feats')\n",
    "            plt.title(f'|Cov(DYX,Z)| after filtering X,Z\\n{D_label}->{Y_label}')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            DYZres = np.concatenate([Dres, Yres, Zres], axis=1)\n",
    "            Zall_cov, Zall_pvals, Zall_thresh = get_cov(DYZres, Xres, get_pvals=True)\n",
    "            plt.subplots(1,1,figsize=(12,8),dpi=60)\n",
    "            sns.heatmap(np.abs(Zall_cov), cmap='Blues')\n",
    "            xtick_labels =[f'D={D_label}', f'Y={Y_label}'] + list(Zint[(Zprm_idx & Zdual_idx)])  # First N are xi, last one is D\n",
    "            plt.yticks(ticks=np.arange(Zres.shape[1]+2)+.5, labels=xtick_labels, rotation=0)\n",
    "            ytick_labels = list(Xint[(Xprm_idx & Xdual_idx)])\n",
    "            plt.xticks(ticks=np.arange(Xres.shape[1])+.5, labels=wrap_labels(ytick_labels,50),rotation=90, fontsize=10)\n",
    "            plt.ylabel('Z feats')\n",
    "            plt.xlabel('X feats')\n",
    "            plt.title(f'|Cov(DYZ,X| after filtering X,Z\\n{D_label}->{Y_label}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretable X, Z features \n",
    "X, X_feats, Z, Z_feats = load_XZ_data()\n",
    "Xint = get_int_feats(X_feats)\n",
    "Zint = get_int_feats(Z_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Production "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Step 1. We need to pick `popular_Z_thresh` and optionally `min_Z_assns_per_X`\n",
    "`popular_Z_thresh`: we want to pick the minimal number of Z feats = Z' such that cov(Z', X) still linearly span cov(D, X). Thus we crudely only look at the features Z that have a nonzero covariance with at least `popular_Z_thresh` # X's. Choose this number to be the minimal set such that cov(D, Xi) still has some Zj for all Xi. This might be a different number for each D. \n",
    "\n",
    "<!-- IGNORE FOR NOW:\n",
    "`min_Z_assns_per_X`: we trivially suggest removing all X feats that have no Z feature associations (an alternative I haven't looked into would be to add on Zs). We can also choose to remove X feats that have < `popular_Z_thresh` Z feats associated with it. Default is to only remove  < `popular_Z_thresh` = 1. \n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "XZ_hparam_plot(dual_or_primal='dual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "XZ_hparam_plot(dual_or_primal='primal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Step 2. Identify weak X and Z proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_weak_XZ_proxies(popular_Z_thresh: int, dual_or_primal='dual', verbose:bool=False):\n",
    "    ''' \n",
    "    For dual, checks if cov(D,X) in span( cov(X,Z) ). \n",
    "    A nonzero covariance is converted into a binary outcome\n",
    "    by a spearman association test where pval < .05/m for\n",
    "    Bonferroni corrected m.\n",
    "    \n",
    "    For primal, cov(Y,Z) in span( cov(Z,X))\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dual_or_primal: str\n",
    "        Tests for violations in either dual or primal. \n",
    "    verbose : bool\n",
    "        Print for interpretability\n",
    "    popular_Z_thresh: int \n",
    "        Threshold to set for filtering what Z feats to keep,\n",
    "        based on how \"popular\" it is in terms of # st. sig. \n",
    "        associations with X feats (in dual; for primal, is \n",
    "        X and Z feats respectively)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    All of the below are a nested dictionary, first with Y_label, then with D_label.\n",
    "        The final value is a boolean index denoting which X and Z's should be kept \n",
    "        based on how good of a proxy they are to eachother based on the violation. \n",
    "    \n",
    "    ssDX_dual : Dict[str, Dict[str, np.array]] \n",
    "        if dual: np.array is of size X where each bool item denotes if the \n",
    "            ith X feat is st.sig. associated with D\n",
    "        if primal: np.array is of size Z where each bool item denotes if the \n",
    "            ith Z feat is st.sig. associated with Y\n",
    "        Not used for filtering X,Z as good proxies, but could be useful meta-\n",
    "        data.\n",
    "        \n",
    "    rmX_zeroZ_dual : Dict[str, Dict[str, np.array]]\n",
    "        if dual: np.array is of size X where each bool item denotes if the \n",
    "            ith X feat has 0 Z feats st.sig. associated with it, and thus \n",
    "            should be removed\n",
    "        if primal: np.array is of size Z where each bool item denotes if the \n",
    "            ith Z feat has 0 X feats st.sig. associated with it, and thus \n",
    "            should be removed\n",
    "            \n",
    "    popssZ_dual : Dict[str, Dict[str, np.array]]\n",
    "        Based on threshold set by popular_Z_thresh.\n",
    "        if dual: np.array is of size Z where each bool item denotes if the \n",
    "            ith Z feat has > popular_Z_thresh st.sig. associations with \n",
    "            all X feats, and thus should be kept \n",
    "        if primal: np.array is of size X where each bool item denotes if the \n",
    "            ith X feat has > popular_Z_thresh st.sig. associations with \n",
    "            all Z feats, and thus should be kept \n",
    "    '''\n",
    "    assert dual_or_primal in ['dual', 'primal']\n",
    "    ssDX_dual = {}\n",
    "    rmX_zeroZ_dual= {}\n",
    "    popssZ_dual = {}\n",
    "    \n",
    "    D_labels = ['Female', 'Obese','Black', 'Asian']\n",
    "    if dual_or_primal=='dual':\n",
    "        Y_labels = ['OA']\n",
    "    else:\n",
    "        Y_labels = ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']\n",
    "    \n",
    "    for Y_label in Y_labels:\n",
    "        ssDX_dual[Y_label] = {}\n",
    "        rmX_zeroZ_dual[Y_label] = {}\n",
    "        popssZ_dual[Y_label] = {}\n",
    "        \n",
    "        for D_label in D_labels:\n",
    "            print(f\"{D_label}->{Y_label}\")\n",
    "\n",
    "            Xres, Zres, Yres, Dres = load_res_data(D_label, Y_label)\n",
    "            if dual_or_primal=='dual':\n",
    "                Xfeat_int, Zfeat_int = Xint, Zint\n",
    "                Xrpr, Zrpr, Drpr, Yrpr, label = 'X', 'Z', 'D', 'Y', D_label\n",
    "                XZres_cov, XZres_pvals, XZres_thresh = get_cov(Xres, Zres, get_pvals=True)\n",
    "                DXres_cov, DXres_pvals, DXres_thresh = get_cov(Dres, Xres, get_pvals=True)\n",
    "            else:\n",
    "                Xfeat_int, Zfeat_int = Zint, Xint\n",
    "                Xrpr, Zrpr, Drpr, Yrpr, label = 'Z', 'X', 'Y', 'D', Y_label\n",
    "                XZres_cov, XZres_pvals, XZres_thresh = get_cov(Zres, Xres, get_pvals=True)\n",
    "                DXres_cov, DXres_pvals, DXres_thresh = get_cov(Yres, Zres, get_pvals=True)\n",
    "    \n",
    "            # We only care about X feats with st.sig. assn with D (dual)\n",
    "            #        Z feats with st.sig. assn with Y (primal)\n",
    "            ss_DXidx = (DXres_pvals < DXres_thresh).squeeze()\n",
    "            ssDX_dual[Y_label][D_label] = ss_DXidx\n",
    "            \n",
    "            print(f\"Ignored {sum(~ss_DXidx)} {Xrpr} feats due to low assn to {Drpr}={label}\")\n",
    "            if verbose:\n",
    "                for idx in np.where(~ss_DXidx)[0][:5]:\n",
    "                    print(f\"{Xrpr} feat: {Xfeat_int[idx]}\")\n",
    "                    print(f\"\\tCov w/ {Drpr}={label}: {round(DXres_cov.squeeze()[idx], 5)}\")\n",
    "\n",
    "        \n",
    "            # We only keep the Z feats that are sufficiently \"popular\" \n",
    "            # ie. have > popular_Z_thresh st.sig. correlations with all X feats\n",
    "            popular_Zidx = ((XZres_pvals < XZres_thresh).sum(axis=0) > popular_Z_thresh).squeeze()\n",
    "            # Z covariance w/ X feats must be both st.sig. and Z feats must be \"popular\" \n",
    "            ss_popular_Zidx = (XZres_pvals < XZres_thresh).squeeze() & popular_Zidx[None, :]\n",
    "            popssZ_dual[Y_label][D_label] = popular_Zidx\n",
    "            print(f\"Keeping {popular_Zidx.sum()} {Zrpr} feats w/ > {popular_Z_thresh} influences\")\n",
    "            \n",
    "            # By default, all Xs are kept\n",
    "            rmX_zeroZ_dual[Y_label][D_label] = np.zeros(ss_DXidx.shape).astype(bool)\n",
    "            if not verbose:\n",
    "                rmX_zeroZ_dual[Y_label][D_label][(ss_popular_Zidx.sum(axis=1) == 0) |  ~ss_DXidx] = True\n",
    "            else:\n",
    "                # Only look at X feats w/ nonzero D association\n",
    "                for idx in np.where(ss_DXidx)[0]:\n",
    "                    if verbose and idx < 10:\n",
    "                        print(\"~\"*10)\n",
    "                        print(f\"{Xrpr} feat: {Xfeat_int[idx]}\")\n",
    "                        print(f\"\\tCov w/ {Drpr}={label}: {round(DXres_cov.squeeze()[idx], 5)}\")\n",
    "\n",
    "                    # If this X feat has no st.sig. Z associations, put in rm list\n",
    "                    if sum(ss_popular_Zidx[idx]) == 0:\n",
    "                        rmX_zeroZ_dual[Y_label][D_label][idx] = True\n",
    "                    else: \n",
    "                        if verbose and idx < 10:\n",
    "                            print(f\"{Zrpr} feats w/ highest cov. to {Xrpr} feat ({sum(ss_popular_Zidx[idx])} found):\")\n",
    "                            sorted_XZ_idx = np.argsort(np.abs(XZres_cov)[idx])[::-1]\n",
    "                            sorted_XZ_idx = np.array([x for x in sorted_XZ_idx if ss_popular_Zidx[idx,x]])[:5]\n",
    "                            for j in sorted_XZ_idx:\n",
    "                                print(f'\\t{Zfeat_int[j]}: {round(XZres_cov[idx, j], 5)}')\n",
    "            print(f\"{Xrpr} feats w/out any {Zrpr} assns: {Xfeat_int[rmX_zeroZ_dual[Y_label][D_label]]}\")\n",
    "            print()\n",
    "    return ssDX_dual, rmX_zeroZ_dual, popssZ_dual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssDX_dual, rmX_zeroZ_dual, popssZ_dual = id_weak_XZ_proxies(dual_or_primal=\"dual\", verbose=False, popular_Z_thresh=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssYZ_primal, rmZ_zeroX_primal, popssX_primal = id_weak_XZ_proxies(dual_or_primal=\"primal\", verbose=False, popular_Z_thresh=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "XZ_vis_cov(rmX_zeroZ_dual, popssZ_dual, rmZ_zeroX_primal, popssX_primal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When N = 35 \n",
    "for D_label in ['Female', 'Obese','Black', 'Asian']:\n",
    "#     for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "    for Y_label in ['OA', 'myoc', 'deprs', 'back']:\n",
    "        print(f\"{D_label}->{Y_label}\")\n",
    "        W, W_feats, X, X_feats, Z, Z_feats, Y, D = load_ukbb_data(D_label=D_label, Y_label=Y_label)\n",
    "\n",
    "#         np.random.seed(4)\n",
    "#         est = ProximalDE_UKBB(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "#                     multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "#         est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label)                \n",
    "#         sm = est.summary(decimals=5)\n",
    "#         print(\"OLD:\")\n",
    "#         print(sm.tables[0])\n",
    "#         print(sm.tables[2])   \n",
    "                \n",
    "        Xprm_idx = popssX_primal[Y_label][D_label]    \n",
    "        Zprm_idx = ~rmZ_zeroX_primal[Y_label][D_label]\n",
    "        \n",
    "        Zdual_idx = popssZ_dual['OA'][D_label]   \n",
    "        Xdual_idx = ~rmX_zeroZ_dual['OA'][D_label]\n",
    "        np.random.seed(4)\n",
    "        est = ProximalDE(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "                    multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "        est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label, \n",
    "                Zres_idx=(Zprm_idx & Zdual_idx), Xres_idx=(Xprm_idx & Xdual_idx))                \n",
    "        sm = est.summary(decimals=5)\n",
    "        print(\"New:\")\n",
    "        print(sm.tables[0])\n",
    "        print(sm.tables[2])   \n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for D_label in ['Female', 'Obese','Black']:\n",
    "    for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "        print(f\"{D_label}->{Y_label}\")\n",
    "        W, W_feats, X, X_feats, Z, Z_feats, Y, D = load_ukbb_data(D_label=D_label, Y_label=Y_label, W='lite')\n",
    "\n",
    "#         np.random.seed(4)\n",
    "#         est = ProximalDE_UKBB(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "#                     multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "#         est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label)                \n",
    "#         sm = est.summary(decimals=5)\n",
    "#         print(\"OLD:\")\n",
    "#         print(sm.tables[0])\n",
    "#         print(sm.tables[2])   \n",
    "                \n",
    "        Xprm_idx = popssX_primal[Y_label][D_label]    \n",
    "        Zprm_idx = ~rmZ_zeroX_primal[Y_label][D_label]\n",
    "        \n",
    "        Zdual_idx = popssZ_dual['OA'][D_label]   \n",
    "        Xdual_idx = ~rmX_zeroZ_dual['OA'][D_label]\n",
    "        \n",
    "        np.random.seed(4)\n",
    "        est = ProximalDE(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "                    multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "        est.fit(W, D, Z, X, Y, D_label=D_label, \n",
    "                Y_label=Y_label, Zres_idx=(Zprm_idx & Zdual_idx), \n",
    "                Xres_idx=(Xprm_idx & Xdual_idx), save_fname_addn='_lite')                \n",
    "        sm = est.summary(decimals=5)\n",
    "        print(\"New:\")\n",
    "        print(sm.tables[0])\n",
    "        print(sm.tables[2])   \n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for D_label in ['Black']:\n",
    "    for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "        try:\n",
    "            print(f\"{D_label}->{Y_label}\")\n",
    "            W, W_feats, X, X_feats, Z, Z_feats, Y, D = load_ukbb_data(D_label=D_label, Y_label=Y_label)\n",
    "\n",
    "            Xprm_idx = popssX_primal[Y_label][D_label]    \n",
    "            Zprm_idx = ~rmZ_zeroX_primal[Y_label][D_label]\n",
    "\n",
    "            Zdual_idx = popssZ_dual['OA'][D_label]   \n",
    "            Xdual_idx = ~rmX_zeroZ_dual['OA'][D_label]\n",
    "            np.random.seed(4)\n",
    "            est = ProximalDE(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "                        multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "            est.fit(W, D, Z, X, Y, D_label=D_label, \n",
    "                    Y_label=Y_label,try_split='Z')                \n",
    "            sm = est.summary(decimals=5)\n",
    "            print(\"New:\")\n",
    "            print(sm.tables[0])\n",
    "            print(sm.tables[2])   \n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "svalues, svalues_crit = est.covariance_rank_test(calculate_critical=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"D={D_label}_Y={Y_label}\\nNumber of singular values above threshold: {np.sum(svalues >= svalues_crit)}. \"\n",
    "          f\"\\nThreshold={svalues_crit:.3f}. Top singular value={svalues[0]:.3f}\")\n",
    "plt.scatter(np.arange(len(svalues)), svalues)\n",
    "plt.axhline(svalues_crit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for D_label in ['Female', 'Obese','Black', 'Asian']:\n",
    "    for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "        print(f\"{D_label}->{Y_label}\")\n",
    "\n",
    "        Xprm_idx = popssX_primal[Y_label][D_label]    \n",
    "        Zprm_idx = np.ones(Zres.shape[1]).astype(bool)\n",
    "        Zprm_idx[rmZ_zeroX_primal[Y_label][D_label]] = False\n",
    "        \n",
    "        Zdual_idx = popssZ_dual[D_label]   \n",
    "        Xdual_idx = np.ones(Xres.shape[1]).astype(bool)\n",
    "        Xdual_idx[rmX_zeroZ_dual[D_label]] = False\n",
    "        \n",
    "#         print(Xint[~(Xprm_idx & Xdual_idx)])\n",
    "        print(Zint[(Zprm_idx & Zdual_idx)])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for D_label in ['Female', 'Obese','Black', 'Asian']:\n",
    "    for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "        print(f\"{D_label}->{Y_label}\")\n",
    "        W, W_feats, X, X_feats, Z, Z_feats, Y, D = load_ukbb_data(D_label=D_label, Y_label=Y_label)\n",
    "\n",
    "#         np.random.seed(4)\n",
    "#         est = ProximalDE(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "#                     multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "#         est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label)                \n",
    "#         sm = est.summary(decimals=5)\n",
    "#         print(\"OLD:\")\n",
    "#         print(sm.tables[0])\n",
    "#         print(sm.tables[2])   \n",
    "                \n",
    "        Xprm_idx = popssX_primal[Y_label][D_label]    \n",
    "        Zprm_idx = np.ones(Zres.shape[1]).astype(bool)\n",
    "        Zprm_idx[rmZ_zeroX_primal[Y_label][D_label]] = False\n",
    "        \n",
    "        Zdual_idx = popssZ_dual[D_label]   \n",
    "        Xdual_idx = np.ones(Xres.shape[1]).astype(bool)\n",
    "        Xdual_idx[rmX_zeroZ_dual[D_label]] = False\n",
    "        \n",
    "                \n",
    "        np.random.seed(4)\n",
    "        est = ProximalDE(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "                    multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "        est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label, Zres_idx=(Zprm_idx & Zdual_idx))                \n",
    "        sm = est.summary(decimals=5)\n",
    "        print(\"Zonly:\")\n",
    "        print(sm.tables[0])\n",
    "        print(sm.tables[2])   \n",
    "        np.random.seed(4)\n",
    "        est = ProximalDE(cv=3, semi=True, dual_type='Z', ivreg_type='adv',\n",
    "                    multitask=False, n_jobs=-1, random_state=3, verbose=1)\n",
    "        est.fit(W, D, Z, X, Y, D_label=D_label, Y_label=Y_label, Xres_idx=(Xprm_idx & Xdual_idx))                \n",
    "        sm = est.summary(decimals=5)\n",
    "        print(\"Xonly:\")\n",
    "        print(sm.tables[0])\n",
    "        print(sm.tables[2])  \n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From this we choose \n",
    "# popular_Z_thresh = {'Female': 20, 'Obese': 30, 'Black': 20, \"Asian\": 20}\n",
    "# popular_Z_thresh = {'Female': 5, 'Obese': 5, 'Black': 5, \"Asian\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_label = 'OA'\n",
    "for D_label in ['Female', 'Obese','Black', 'Asian']:\n",
    "    print(\"\\n\" + \"#\"*20)\n",
    "\n",
    "    print(D_label)\n",
    "    Xres, Zres, Yres, Dres = load_res_data(D_label, Y_label)\n",
    "    DXres_cov, DXres_pvals, DXres_thresh = get_cov(Dres, Xres, get_pvals=True)\n",
    "    \n",
    "    # We only care about X feats with st.sig. assn with D\n",
    "    ss_DXidx = (DXres_pvals < DXres_thresh).squeeze()\n",
    "    \n",
    "    ssDX_dual[D_label] = ss_DXidx\n",
    "    rmX_zeroZ_dual[D_label] = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Ignored {sum(~ss_DXidx)} X feats due to low assn to D={D_label}\")\n",
    "        for idx in np.where(~ss_DXidx)[0][:2]:\n",
    "            print(f\"X feat: {Xint[idx]}\")\n",
    "            print(f\"\\tCov w/ D={D_label}: {round(DXres_cov.squeeze()[idx], 5)}\")\n",
    "    \n",
    "    # W the same for D in [Black, Asian] so can reuse XZres\n",
    "    if D_label != 'Asian':\n",
    "        XZres_cov, XZres_pvals, XZres_thresh = get_cov(Xres, Zres, get_pvals=True)\n",
    "\n",
    "    popular_Zidx = ((XZres_pvals < XZres_thresh).sum(axis=0) > popular_Z_thresh[D_label])\n",
    "    popssZ_dual[D_label] = popular_Zidx.squeeze()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Keeping {popular_Zidx.sum()} Z feats w/ > {popular_Z_thresh[D_label]} influences\")\n",
    "\n",
    "    # Only look at X feats w/ nonzero D association\n",
    "    for idx in np.where(ss_DXidx)[0]:\n",
    "        print(\"\\n\" + \"~\"*10)\n",
    "        print(f\"X feat: {Xint[idx]}\")\n",
    "        print(f\"\\tCov w/ D={D_label}: {round(DXres_cov.squeeze()[idx], 5)}\")\n",
    "\n",
    "        # Which Z feats have st.sig. assn for each X feat idx? \n",
    "        ss_Zidx = (XZres_pvals[idx].squeeze() < XZres_thresh) \n",
    "        # Filter to keep only the most \"popular\" Z feats\n",
    "        ss_popular_Zidx = ss_Zidx & popular_Zidx\n",
    "        \n",
    "        \n",
    "        if verbose and sum(ss_Zidx) != sum(ss_popular_Zidx):\n",
    "            print(f\"Keeping only popular Z's {sum(ss_Zidx) } -> {sum(ss_popular_Zidx)} ss Z feats w/ this X\")\n",
    "\n",
    "        if sum(ss_popular_Zidx) == 0:\n",
    "            print(\"ERROR: X FEAT HAS NO ASSD Z FEATS\")\n",
    "            rmX_zeroZ_dual[D_label].append(idx)\n",
    "        else: \n",
    "            if verbose:\n",
    "                print(f\"Z feats w/ highest cov. to X feat ({sum(ss_popular_Zidx)} found):\")\n",
    "                sorted_XZ_idx = np.argsort(np.abs(XZres_cov)[idx])[::-1]\n",
    "                sorted_XZ_idx = np.array([x for x in sorted_XZ_idx if ss_popular_Zidx[x]])[:2]\n",
    "                for j in sorted_XZ_idx:\n",
    "                    print(f'\\t{Zint[j]}: {round(XZres_cov[idx, j], 5)}')\n",
    "    print(f\"Consider removing these X feats, which don't have any Z assns: {Xint[np.array(rmX_zeroZ_dual[D_label])]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(XZres_cov.flatten(), label='before', alpha=.4, bins=50, density=True)\n",
    "plt.hist(XZres_cov[XZres_pvals < XZres_thresh].flatten(),alpha=.4, bins=50, label='after', density=True)\n",
    "plt.legend()\n",
    "plt.title(\"XZ covariances before and after pvalue filtering (residual XZ)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "# OLD: Primal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X feats that don't really influence any Z feats\n",
    "get_int_feats(X_feats[((XZres_pvals < XZres_thresh).sum(axis=1) < 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X feats that really influence any Z feats\n",
    "get_int_feats(X_feats[((XZres_pvals < XZres_thresh).sum(axis=1) > 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "popular_X_thresh = 5\n",
    "ssYZ_primal = {}\n",
    "rmZ_zeroX_primal = {}\n",
    "popssX_primal = {}\n",
    "for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "    ssYZ_primal[Y_label] = {}\n",
    "    rmZ_zeroX_primal[Y_label] = {}\n",
    "    popssX_primal[Y_label] = {}\n",
    "    \n",
    "    for D_label in ['Female', 'Obese','Black', 'Asian']:\n",
    "\n",
    "        print(\"\\n\" + \"#\"*20)\n",
    "\n",
    "        print(Y_label, D_label)\n",
    "        Xres, Zres, Yres, Dres = load_res_data(D_label, Y_label)\n",
    "        YZres_cov, YZres_pvals, YZres_thresh = get_cov(Yres, Zres, get_pvals=True)\n",
    "\n",
    "        # We only care about Z feats with st.sig. assn with Y\n",
    "        ss_YZidx = (YZres_pvals < YZres_thresh).squeeze()\n",
    "\n",
    "        ssYZ_primal[Y_label][D_label] = ss_YZidx\n",
    "        rmZ_zeroX_primal[Y_label][D_label] = []\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Ignored {sum(~ss_YZidx)} Z feats due to low assn to Y={Y_label}\")\n",
    "#             for idx in np.where(~ss_Zidx)[0][:3]:\n",
    "#                 print(\"\\n\" + \"~\"*10)\n",
    "#                 print(f\"Z feat: {Zint[idx]}\")\n",
    "#                 print(f\"\\tCov w/ Y={Y_label}: {round(YZres_cov.squeeze()[idx], 5)}\")\n",
    "#                 print(f\"\\tCov w/ D={D_label}: {round(DZres_cov.squeeze()[idx], 5)}\")\n",
    "\n",
    "        ZXres_cov, ZXres_pvals, ZXres_thresh = get_cov(Zres, Xres, get_pvals=True)\n",
    "\n",
    "        # Filter X feats based on how many Z feats the X feat is associated w/\n",
    "        popular_Xidx = ((ZXres_pvals < ZXres_thresh).sum(axis=0) > popular_X_thresh)\n",
    "        popssX_primal[Y_label][D_label] = popular_Xidx.squeeze()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Keeping {popular_Xidx.sum()} X feats w/ > {popular_X_thresh} influences\")\n",
    "\n",
    "        # Only look at Z feats w/ nonzero Y association\n",
    "        for idx in np.where(ss_YZidx)[0]:\n",
    "#             print(\"\\n\" + \"~\"*10)\n",
    "#             print(f\"Z feat: {Zint[idx]}\")\n",
    "#             print(f\"\\tCov w/ Y={Y_label}: {round(YZres_cov.squeeze()[idx], 5)}\")\n",
    "\n",
    "            # Which X feats have st.sig. assn for each Z feat idx? \n",
    "            ss_Xidx = (ZXres_pvals[idx].squeeze() < ZXres_thresh) \n",
    "            # Filter to keep only the most \"popular\" X feats\n",
    "            ss_popular_Xidx = ss_Xidx & popular_Xidx\n",
    "\n",
    "\n",
    "#             if verbose and sum(ss_Xidx) != sum(ss_popular_Xidx):\n",
    "#                 print(f\"Keeping only popular X's {sum(ss_Xidx) } -> {sum(ss_popular_Xidx)} ss X feats w/ this Z\")\n",
    "\n",
    "            if sum(ss_popular_Xidx) == 0:\n",
    "                print(\"ERROR: Z FEAT HAS NO ASSD X FEATS\")\n",
    "                rmZ_zeroX_primal[Y_label][D_label].append(idx)\n",
    "#             else: \n",
    "#                 if sum(ss_popular_Xidx) < min_X_assns_per_Z:\n",
    "#                     rmZ_lowX_primal[Y_label].append(idx)\n",
    "\n",
    "#                 if verbose:\n",
    "#                     print(f\"X feats w/ highest cov. to Z feat ({sum(ss_popular_Xidx)} found):\")\n",
    "#                     sorted_ZX_idx = np.argsort(np.abs(ZXres_cov)[idx])[::-1]\n",
    "#                     sorted_ZX_idx = np.array([x for x in sorted_ZX_idx if ss_popular_Xidx[x]])[:3]\n",
    "#                     for j in sorted_ZX_idx:\n",
    "#                         print(f'\\t{Xint[j]}: {round(ZXres_cov[idx, j], 5)}')\n",
    "        print(f\"Consider removing these Z feats, which don't have any X assns: {Zint[np.array(rmZ_zeroX_primal[Y_label][D_label])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for D_label in ['Black', 'Female', 'Obese','Asian']:\n",
    "#     print(D_label)\n",
    "#     for Y_label in ['OA', 'RA', 'myoc', 'copd', 'deprs', 'back']:\n",
    "D_label = 'Black'\n",
    "Y_label = 'deprs'\n",
    "D, Y = load_DY_data(D_label, Y_label)\n",
    "D, Y = D.reshape(-1, 1), Y.reshape(-1, 1)\n",
    "YZ_cov, YZ_pvals, YZ_thresh = get_cov(Y, Z, get_pvals=True)\n",
    "YZres_cov, YZres_pvals, YZres_thresh = get_cov(Yres, Zres, get_pvals=True)\n",
    "(YZres_pvals < YZres_thresh).mean(), (YZ_pvals < YZ_thresh).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "DZ_cov, DZ_pvals, DZ_thresh = get_cov(D, Z, get_pvals=True)\n",
    "DZres_cov, DZres_pvals, DZres_thresh = get_cov(Dres, Zres, get_pvals=True)\n",
    "(DZres_pvals < DZres_thresh).mean(), (DZ_pvals < DZ_thresh).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z feats with st.sig. assn with Y\n",
    "ss_Zidx = (YZres_pvals < YZres_thresh).squeeze()\n",
    "get_int_feats(Z_feats[~ss_Zidx]), get_int_feats(Z_feats[ss_Zidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.where(~ss_Zidx)[0]:\n",
    "    print(\"\\n\" + \"#\"*20)\n",
    "    print(f\"Z feat: {Zint[idx]}\")\n",
    "    print(f\"\\tCov w/ Y={Y_label}: {round(YZres_cov.squeeze()[idx], 5)}\")\n",
    "    print(f\"\\tCov w/ D={D_label}: {round(DZres_cov.squeeze()[idx], 5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(XZres_pvals[:, ss_Zidx] < XZres_thresh)\n",
    "plt.show()\n",
    "plt.hist((XZres_pvals[:, ss_Zidx] < XZres_thresh).sum(axis=1), bins=20)\n",
    "plt.title(\"X features # st.sig. correlation with each feat of X\\nAfter removing Z feats w/ no Y assn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((XZres_pvals < XZres_thresh).sum(axis=1),bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keep_Xidx_thresh = 20\n",
    "keep_Zidx_thresh = 10\n",
    "zero_Z = []\n",
    "low_Z = []\n",
    "keep_Xidx = ((XZres_pvals < XZres_thresh).sum(axis=1) > keep_Xidx_thresh)\n",
    "print(f\"Only {keep_Xidx.sum()} X feats kept!\")\n",
    "for idx in np.where(ss_Zidx)[0]:\n",
    "    print(\"\\n\" + \"#\"*20)\n",
    "    print(f\"Z feat: {Zint[idx]}\")\n",
    "    print(f\"\\tCov w/ Y={Y_label}: {round(YZres_cov.squeeze()[idx], 5)}\")\n",
    "    print(f\"\\tCov w/ D={D_label}: {round(DZres_cov.squeeze()[idx], 5)}\")\n",
    "    ss_Xidx = (XZres_pvals[:, idx].squeeze() < XZres_thresh) \n",
    "    ss_fltr_Xidx = ss_Xidx & keep_Xidx\n",
    "\n",
    "    if sum(ss_Xidx) != sum(ss_fltr_Xidx):\n",
    "        print(f\"Rm noninfluential X's rd ss # from {sum(ss_Xidx) } -> {sum(ss_fltr_Xidx)}\")\n",
    "\n",
    "    if sum(ss_fltr_Xidx) == 0:\n",
    "        print(\"ERROR: No ss X found!!!\")\n",
    "        zero_Z.append(idx)\n",
    "    else: \n",
    "        if sum(ss_fltr_Xidx) < keep_Zidx_thresh:\n",
    "            low_Z.append(idx)\n",
    "        print(f\"X feats w/ highest cov. to Z feat ({sum(ss_fltr_Xidx)} found):\")\n",
    "        sorted_XZ_idx = np.argsort(np.abs(XZres_cov)[:, idx])[::-1]\n",
    "        sorted_XZ_idx = np.array([x for x in sorted_XZ_idx if ss_fltr_Xidx[x]])[:10]\n",
    "        for j in sorted_XZ_idx:\n",
    "            print(f'\\t{Xint[j]}: {round(XZres_cov[j, idx], 5)}')\n",
    "print(f\"Consider removing these Z feats, which don't have any X assns: {Zint[np.array(zero_Z)]}\")\n",
    "print(f\"\\twhich have low X assns: {Zint[np.array(low_Z)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(popssZ_dual[D_label])\n",
    "(popssZ_dual[D_label].sum(axis=0) > 0).sum(), popular_Zidx.sum(), (popssZ_dual[D_label].sum(axis=1) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "id": "nemTbAS4FZQw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
